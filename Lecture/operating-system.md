# 운영체제

## 운영체제 개요

### 운영체제의 개요

#### 컴퓨터 시스템과 운영체제

1. 하드웨어와 응용 프로그램 사이에 운영체제를 두고 하드웨어 제어는 운영체제만 하도록 하였다

2. 여러 응용 프로그램이 동시에 수행되더라도 운영체제가 중간에서 충돌 없이 자원을 효율적으로 나누어준다

3. 응용 프로그램이 직접 하드웨어에 접근하는 것을 방지하기 위해서 슈퍼바이저 모드와 보호보드가 사용된다.

- > 슈퍼바이저모드(커널모드): 하드웨어를 직접 제어할 수 있는 CPU의 명령어를 사용할 수 있는 모드로 운영체제의 커널이 동작되는 모드

- > 보호모드(사용자모드): 하드웨어를 직접 제어하는 CPU의 명령어를 사용할 수 없는 모드로 응용 프로그램이 동작하는 모드

#### 커널

응용 프로그램과 하드웨어 수준의 처리 사이의 가교 역할을 하는 운영체제의 핵심 요소를 Kernel 이라고 한다.
커널은 운영체제마다 구성 방식이 다른데, 대표적으로 일체형 커널과 마이크로 커널이 있다.

일체형 커널 (monolithic kernel)

- 운영체제의 모든 서비스가 커널 내에 포함된 커널이다.
- 장점은 커널 내부 요소로 존재하는 서비스들이 서로 효율적으로 상호작용 할 수 있다는 것이다.
- 단점은 하나의 요소에서 오류가 발생하면 시스템 전체에 장애를 일으킬 수 있다는 것이다.
- UNIX와 Linux 운영체제가 일체형 커널이다.

마이크로 커널 (micro kernel)

- 운영체제의 대부분 요소들을 커널 외부로 분리하여 커널 내부에는 메모리 관리,멀티태스킹, 프로세스 간 통신(IPC) 등의 최소한의 요소들만 남겨 놓은 커널이다.
- 파일시스템, 장치 드러이버, 네트워크 프로토콜 들은 보호 모드에서 동작하도록 분리된다.
- 장점은 새로운 서비스를 추가하여 운영체제를 확장하기 쉬우며 커널 외부의 요소에 문제가 발생해도 커널 자체에는 영향이 없어 안정성이 우수하다.
- 단점은 커널 외부에 존재하는 운영체제 요소들 사이에 데이터 전달이 필요한 경우에는 IPC를 통해야 하기 때문에 성능저하가 발생한다.

### 운영체제의 구성

#### 프로세스 관리자

프로세스(실행중인 프로그램 또는 작업) 관리자는 프로세스들을 생성하고 삭제하며 CPU에 할당하기 위한 스케줄을 결정한다.
또한 각 프로세스의 상태(준비, 실행, 대기 등)를 관리하며 상태 전이를 처리한다.

#### 메모리 관리자

메모리 관리자는 주기억장치를 관리한다. 요청에 따라 메모리를 할당하고 테이블을 만들어 관리한다. 회수 시점에 메모리를 회수한다.
또 다른 역할은 운영체제가 점유하고 있는 주기억 장치의 공간을 지키는 것이다.

#### 장치 관리자

장치 관리자는 시스템의 모든 장치를 관리한다. 시스템 스케줄링 기법을 기반으로 장치를 효율적으로 할당한다.

#### 파일 관리자

파일 관리자는 시스템의 모든 파일을 관리한다. 또한 파일의 접근 제한을 관리하거나 파일을 열어 자원을 할당하거나 파일을 닫아 자원을 회수한다.

### 운영체제 유형

#### 일괄처리 운영체제

일괄처리(batch processing) 운영체제는 초창기 컴퓨터에서 사용되었던 유형으로 작업을 모아서 처리하는 방식이다.

#### 대화형 운영체제

대화형(interactive) 운영체제는 시분할 운영체제라고도 하며,
응답시간 측면에서 일괄처리 운영체제보다는 빠르지만 실시간 운영체제보다는 느리다.
대화형 운영체제는 이용자에게 즉각적인 피드백을 제공하고 응답시간은 사용 중인 이용자의 수에 따라 수 분 또는 수 초 안에 처리된다.

#### 실시간 운영체제

실시간(real-time) 운영체제는 운영체제 중 가장 빠른 응답시간을 가진다.
데이터의 처리가 빨라야 하는 환경인, 우주 비행 시스템, 미사일 제어, 증권 거래 등의 분야에 사용된다.

#### 하이브리드 운영체제

하이브리드(hybrid) 운영체제는 일괄처리와 대화형 운영체제의 결합으로 볼 수 있다.
각 이용자가 터미널을 통해 접속하고 빠른 응답시간을 얻을 수 있기 때문에 대화형이지만,
작업량이 많지 않을 경우 운영체제는 백그라운드에서 배치 프로그램을 받아들이고 실행한다.
현재 사용되고 있는 대부분의 대형 컴퓨터 시스템은 하이브리드 운영체제라고 할 수 있다.

## 프로세스 개요

### 프로세스

프로세스란 실행 중인 프로그램을 의미함
프로그램을 실행시키려면 운영체제로부터 동작하는데 필요한 CPU, 메모리, 입출력장치, 파일 등의 자원을 할당받아야 한다.

프로세스는 사용자가 실행시킨 프로그램 뿐만 아니라 스풀링과 같은 시스템 태스크도 각각 하나의 프로세스 이다.

운영체제는 프로세스의 상태를 관리하며 필요한 경우 프로세스가 다른 상태로 전이되도록 처리한다.

#### 프로세스의 상태 변화

프로세스는 `생성 -> [ 준비, 실행, 대기 ] -> 종료`의 다섯가지 중 하나의 상태를 가진다.

1. 생성 -> 준비 : 정의된 정책에 따라 스케줄러에 의해 호출된다. 이용가능한 메모리와 요구 장치를 검사한다.
2. 준비 -> 실행 : 사전에 정의된 알고리즘 (FCFS, SJF, SRT, RR ...)에 따라 스케줄러에 의해 처리된다 (dispatch)
3. 실행 -> 준비 : 할당 시간의 만료나 우선순위 알고리즘 채택시 높은 우선순위의 프로세스가 오는 경우 후순위로 처리된다.
4. 실행 -> 대기 : I/O 요구, 페이지 교환요구 같은 작업에 의해 일어난다. 이러한 작업은 상대적으로 오랜시간이 걸리므로 그 동안 다른 프로세스에 자원을 할당한다.
5. 대기 -> 준비 : I/O 장치 관리자의 신호에 의해 일어난다. 페이지 교환의 경우 페이지 인터럽트 핸들러가 메모리에 페이지가 있다는 신호를 보내면 프로세스는 준비큐에 놓이게 된다.
6. 실행 -> 종료 : 프로세스를 정상 종료하거나 에러발생시 강제종료시 스케줄러에 의해 수행된다.

#### 프로세스 제어 블록

프로세스의 관리를 위해서 운영체제는 각 프로세스 마다 프로세스 제어 블록 (PCB)을 두고 프로세스 정보를 보관한다.

1. 프로세스 상태
2. 프로세스 번호(PID)
3. 프로그램 카운터(PC): 프로세스 수행을 위한 다음명령의 주소 표시
4. 레지스터(register): CPU의 레지스터에 해당하는 정보를 포함한다. 실행상태에서 다른 상태로 전의되는 경우 CPU의 레지스터 정보를 저장하여 나중에 다시 실행상태로 전이될 때 복구하여 프로세스 수행을 계속할 수 있게 한다.
5. 메모리: 프로세스가 저장된 주소와 가상메모리의 가상주소, 실제 주소의 mapping 정보, base register와 bound register 등의 정보를 포함
6. 프로세스 우선순위: 우선순위 스케줄링시 어떤 작업을 선택할 것인지에 대한 정보
7. 회계정보: 성능 측정과 순위에 대한 정보 - CPU 사용시간, 프로세스 존재시간, 메모리사용량 ...

#### 프로세스 생성과 종료

##### 프로세스 생성

프로세스는 프로세스 생성 시스템 호출을 이용하여 어러 개의 프로세스를 호출 할 수 있다.
이 프로세스를 부모 프로세스라 하고, 생성된 새로운 프로세스는 자식 프로세스라 한다.
부모 프로세스는 자식 프로세스에 자원을 나누어 주거나 공유할 수 있다.
물리/논리적 자원을 얻는 것 이외에도 몇몇 초기화 데이터가 부모 프로세스에서 자식 프로세스로 전달된다.

프로세스 생성을 위해서는 프로세스 이름 결정, 프로세스 준비 큐에 삽입, 우선순위 부여, 프로세스 제어블록 생성 등이 필요하다.

##### 프로세스 종료

프로세스는 마지막 문장이 끝났을 때 종료된다. 이때 프로세스는 부모 프로세스에게 실행결과를 되돌려준다.
또한 프로세스가 종료될 때 또 다른 상황이 발생할 수도 있다. (`exit()`와 같은 시스템 호출로 다른 자식프로세스를 종료...)

부모 프로세스는 다음과 같은 이유로 자식 프로세스를 종료할 수 있다.

1. 자식 프로세스가 할당된 자원의 사용 초과 (자식 프로세스의 상태를 검사할 수 있어야 함)
2. 자식 프로세스에게 할당된 작업이 더 이상 필요하지 않을 때

마지막으로 어떤 프로세스가 종료된다면 자식 프로세스는 모두 종료된다 이를 cascading termination 이라하고 OS에 의해 실행된다.

#### 프로세스 간의 관계

##### 독립적 프로세스

independent process란 시스템에서 실행중인 다른 프로세스의 영향을 받지도 주지도 않는 프로세스를 의미한다.
일반적으로 다른 프로세스와 데이터를 공유하지 않는 프로세스는 독립적이다.

1. 프로세스의 상태는 다른 프로세스와 공유되지 않는다.
2. 프로세스의 실행결과는 입력상태에 의해서만 결정된다.
3. 프로세스의 실행은 같은 입력에 대하여 항상 동일하다.
4. 프로세스의 실행은 타 프로세스와 무관하게 중된되거나 재시작될 수 있다.

#### 유기적 프로세스

cooperating process란 실행중인 다른 프로세스와 영향을 주고 받으며 동작하는 프로세스이다.
일반적으로 다른 프로세스와 데이터를 공유하는 프로세스는 유기적 프로세스 이다.

1. 프로세스의 상태는 다른 프로세스와 공유된다.
2. 프로세스의 실행결과는 실행순서에 좌우되므로 미리 예측할 수 없다.
3. 프로세스의 실행결과는 동일한 입력에 대하여 동일함을 보장하지 않는다.

### 쓰레드 (Thread)

일반적으로 다중 프로세싱 시스템에서 기본적 처리단위는 프로세스이다.
하나의 프로그램을 수행하기 위해 하나의 주소공간과 주소공간내에서 하나의 제어흐름으로 구성된 프로세스를 사용한다.
하나의 프로세스 내에서 프로그램이 수행될 때 각각의 실행 단위 시간안에 하나의 실행점만이 존재한다.
즉 단일 프로세스 내에서 동시/병렬 처리가 불가능하다.

쓰레드는 프로세스 내에서 다중처리를 위하여 제안된 개념으로, 실행 단위를 프로세스에서 한 단계 낮추어 규정한 것이다.

기존의 개념에서 프로세스는 자원 소유의 단위와 디스패칭의 단위로 설명될 수 있다.
최근에 개발된 많은 운영체제에서는 디스패칭의 단위를 보통 쓰레드 혹은 경량 프로세스라 하고, 자원 소유의 단위는 그대로 프로세스 또는 작업이라 부르고 있다.

쓰레드는 제어의 흐름을 의미하고 프로세스에서 실행의 개념만을 분리한 것

쓰레드 내에서는 하나의 실행점만 존재하고, 각 쓰레드는 프로그램 카운터와 스택, 쓰레드 관리 정보등과 같은 최소한의 정보만으로 구성된다.
쓰레드도 프로세스와 마찬가지로 생성 후 준비, 실행, 대기 상태를 거친 후 종료상태에 이르게된다.

### 스케줄링

스케줄링이란 여러가지 작업들의 처리순서를 결정하는 것을 의미한다.

#### 스케줄링 단계

##### 상위단계 스케줄링

시스템에 들어오는 작업들을 선택하여 프로세스를 생성한 후 프로세스 준비 큐에 전달

##### 하위단계 스케줄링

사용가능한 CPU를 준비상태의 어느 프로세스에 배당할지를 결정

CPU를 배당받은 프로세스는 실행상태가 된다.
이렇게 프로세스가 준비상태에서 실행상태로 바뀌는 것을 dispatch라 하고, 하위단계 스케줄링의 실행주체는 dispatcher가 된다.

하위 단계 스케줄링은 빈번하게 일어나므로 dispatcher는 메모리에 상주해야 한다.

##### 중간단계 스케줄링

프로세스를 일시적으로 메모리에서 제거하여 중지 시키거나 다시 활성화 시켜서 시스템에 대한 단기적 부하를 조절한다.

#### 스케줄링 정책

운영체제의 목적(처리량 극대화, 반환시간 최소화, CPU 활용의 극대화, 빠른 응답시간 ...)에 맞춰 프로세스에게 자원을 할당한다.

##### 선점 스케줄링 정책 (preemptive scheduling policy)

진행 중인 작업에 인터럽트를 걸고 다른 작업에 CPU를 할당하는 스케줄링 전략이다.
선점 스케줄링 방식은 시간 할당 방식에서 주로 사용된다.

높은 우선순위의 프로세스가 긴급한 경우 유용하다. 또한 필요 프로세스가 자원을 선점하므로 예측가능하다.
하지만 프로세스를 종료하지 않은채 자원을 다른 프로세스에 할당하려면 문맥교환이 필요하므로 오버헤드가 발생한다.

문맥교환(context switching)이란 CPU가 현재 실행하고 있는 프로세스의 context를 프로세스 제어블록(PCB)에 저장하고,
다음 프로세스의 PCB로 부터 context를 복원하는 작업을 의미한다.

##### 비선점 스케줄링 정책 (nonpreemptive scheduling policy)

프로세스가 CPU를 할당받아 실행이 시작되면 프로세스 자체가 I/O 인터럽트를 걸거나 프로세스를 종료할 때 까지
(예외적으로 무한루프를 숭해중인 경우 선점/비선점에 관계없이 인터럽트가 걸린다) 실행상태에 있게 된다.

우선순위에 관계없이 대기 중인 프로세스는 변동이 없으므로 응답시간 예측이 가능하다.

## 스케줄링 알고리즘

### 스케줄링 성능 평가 기준

평균 대기시간: 각 프로세스가 수행이 완료될 때까지 준비 큐에서 기다리는 시간합의 평균

평균 반환시간: 각 프로세스가 생성된 시점부터 수행이 완료된 시점까지의 소요시간의 평균

### FCFS 스케줄링

First Come First Served 스케줄링은 비선점 방법이다.

프로세스는 준비 큐에서 도착순서에 따라 디스패치되며,
일단 한 프로세스가 CPU를 차지하면 그 프로세스의 수행이 완료된 후에 다음 프로세스가 수행된다.

| 프로세스 | CPU사이클 |
|---|---|
| A | 6 |
| B | 3 |
| C | 1 |
| D | 4 |

4개의 프로세스가 A B C D 순서로 거의 동시에 입력되었다면 FCFS 스케줄에서 실행순서는

1. 0~6: A
2. 6~9: B
3. 9~10: C
4. 10~14: D

평균 대기시간: (0+6+9+10)/4 = 6.25

평균 반환시간: (6+9+10+14)/4 = 9.75

FCFS 알고리즘은 짧은 작업이 긴 작업을 기다리기도 하고 중요한 프로세스가 나중에 수행될 수도 있다.
또한 프로세스들의 도착 순서에 따라 평균 반환시간이 크게 변하는 단점도 있다. 따라서 대화형 시스템에 사용하지 않는다.

최근 시스템에서 FCFS 스케줄링은 주요 방법이 아니라 다른 방법과 결합하여 쓰이고 있다.

### SJF 스케줄링

SJF(Shortest Job First) 스케줄링은 준비큐에서 기다리는 프로세스 중
실행시간이 가장 짧다고 예상된 것을 먼저 디스패치 하여 실행하는 비선점 스케줄링 알고리즘이다.

| 도착시간 | 프로세스 | CPU사이클 |
|---|---|---|
| 0 | A | 6 |
| 1 | B | 3 |
| 2 | C | 1 |
| 3 | D | 4 |

1. 0~6: A
2. 6~7: C
3. 7~10: B
4. 10~14: D

평균 대기시간: (0+6+4+7)/4 = 4.25

평균 반환시간: (6+9+5+11)/4 = 7.75

SJF 스케줄링 알고리즘의 문제점은 실행 예정 시간 길이를 사용자의 추정치에 의존하므로
실제로 먼저 처리할 작업의 CPU 시간을 에상할 수 없다. 따라서 대화형 시스템에 사용 하지 않는다.

### SRT 스케줄링

SRT(Shortest Remaining Time) 스케줄링은 SJF 알고리즘의 선점(preemptive) 알고리즘 버전이다.
새로 들어오는 프로세스를 포함하여 실행이 끝날 때까지 남은 시간 추정치가 가장 짧은 프로세스를 먼저 디스패치한다.
대화형 운영체제에서 유용한 방식이다.

| 도착시간 | 프로세스 | CPU사이클 |
|---|---|---|
| 0 | A | 6 |
| 1 | B | 3 |
| 2 | C | 1 |
| 3 | D | 4 |

1. 0~1: A
2. 1~2: B
3. 2~3: C
4. 3~5: B
5. 5~9: D
6. 9~14: A

평균 대기시간: (8+1+0+2)/4 = 2.75

평균 반환시간: (14+4+1+6)/4 = 6.25

SRT는 SJF보다 평균 대기시간이나 평균 반환시간면에서 효율적이다.
하지만 SRT는 실행되는 각 작업을 추적하여 서비스를 받은 시간이 기록되어야 하며
선점을 위한 문맥 교환도 필요하므로 SJF보다 오버헤드가 크다.

이러한 상황은 임계치(threshold value)를 설정하여 해결하는데,
만일 실행중인 작업이 완료되기까지 남은 시간이 임계치 보다 작다면 시스템은 그 작업을 계속 실행하게 하는것이다.

### RR 스케줄링

RR(Round Robin) 스케줄링은 대화형 시스템에서 사용되는 선점 스케줄링 방식이다.
프로세스가 도착한 순서대로 프로세스를 디스패치 하지만 정해진 시간 안에 완료하지 못한 프로세스는 다시 준비큐의 맨 뒤에 배치한다.

| 도착시간 | 프로세스 | CPU사이클 |
|---|---|---|
| 0 | A | 6 |
| 1 | B | 3 |
| 2 | C | 1 |
| 3 | D | 4 |

시간 할당량을 3으로 둔다면

1. 0~3: A
2. 3~6: B
3. 6~7: C
4. 7~10: D
5. 10~13: A
6. 13~14: D

평균 대기시간: (7+2+4+7)/4 = 5

평균 반환시간: (13+5+5+11)/4 = 8.5

RR스케줄링 알고리즘의 성능은 평균 CPU 소요시간에 대한 시간간격의 길이에 따라 달라진다.
간격이 너무 큰경우에는 FCFS 정도로 성능이 낮아질 것이다.
간격이 너무 짧은 경우 잦은 문맥 교환이 작업 수행을 방해하여 오버헤드가 크게 증가한다.

따라서 가장 적절한 시간 간격은 시스템 형태에 따라 최적화 되어야 한다.

적절한 시간 간격을 결정하는 데는 일반적인 규칙 두 가지가 있다.
첫째, 80%의 CPU 사이클을 처리할 수 있또록 하는 것. 둘째, 한 번의 문맥 교환에 걸리는 시간보다 100배 정도는 길어야 한다.

### HRN 스케줄링

HRN(Highest Response Ratio Next) 스케줄링은 준비 큐에서 기다리는 프로세스 중
응답비율이 가장 큰 것을 먼저 디스패치 하여 실행하는 비선점 스케줄링 알고리즘이다.

`응답비율 = (대기시간 + 예상 실행시간) / 예상 실행시간 = 대기시간/예상실행 시간 + 1`

| 도착시간 | 프로세스 | CPU사이클 |
|---|---|---|
| 0 | A | 6 |
| 1 | B | 3 |
| 4 | C | 2 |
| 6 | D | 1 |

1. A 실행: 응답비율 = (0+6)/6 =1
2. A 실행 중 B((5+3)/3=2.67), C((2+2)/2=2), D((0+1)/1 = 1) 도착
3. 응답비율이 큰 B를 실행
4. 응답비율이 큰 D를 실행
5. 마지막으로 C를 실행

HRN 스케줄링은 SJF 스케줄링의 단점을 보완한 것이다.
HRN 스케줄링은 실행시간이 긴 프로세스라 하더라도 대기시간이 길어지면 응답비율도 커져서
실행시간이 짧은 프로세스가 들어오더라도 우선순위에서 밀리지 않을 수 있다.

### 다단계 피드백 큐 스케줄링

다단계 피드백 큐 스케줄링은 선점 스케줄링 방식으로,
입출력 중심인 프로세스와 CPU 중심인 프로세스의 특성에 따라 서로 다른 시간 할당량을 부여한다.

다단계 피드백 큐 스케줄링은 n개의 단계가 있는경우, 각 단계마다 하나씩의 큐가 존재한다.
단계 `k`는 단계 `k+1`에 피드백을 주며 단계가 커질수록 시간 할당량은 커지는 형태로 구성되어 있다.

프로세스가 도착하면 단계 1의 큐에 들어간다.
이후 큐에 도착한 순서대로 프로세스들이 처리되다가 자신의 차례가 되면 해당 프로세스는 디스패치 되어 단계 1의 시간할당량 만큼 실행된다.

시간할당량보다 짧은 시간에 프로세스가 끝나면 완료가 되고, 입출력 같은 이벤트가 발생하면 CPU를 양보하고 대기상태로 갔다가
다시 준비상태가 될 때에는 현재와 동일한 단계의 큐에 배치된다.
만약 시간 할당량을 다 썼지만 프로세스가 종료되지 못했다면 다음단계 큐로 이동 배치된다.

반복하여 마지막 단계 n에서도 단계 n의 시간 할당량만큼 실행한 후 종료되지 못한경우에는 계속하여 동일한 단계 n의 큐에 배치된다.
마지막 단계만 보면 RR 스케줄링 방식과 동일하다.

결국 연산 위주의 프로세스는 점점 단계가 커지게 되고, 입출력 위주의 프로세스는 앞부분의 단계를 유지하게 된다.

다단계 피드백 큐 스케줄링 알고리즘의 변형으로 적응적 스케줄링 기법을 적용할 수 있다.
이는 프로세스의 유동적 상태 변화에 적응한다는 의미로,
기본적으로 동일한 프로세스는 마지막에 있었던 단계의 큐로 배치가 되고 한 번 단계가 커지면 반대로 돌아갈 방법이 없지만,

적응적 기법에서는 시간 할당량을 다 쓰기 전에 CPU를 반납하는 경우 하나 작은 단계의 큐로 되돌아 갈 수 있다.
따라서 연산 위주의 작업을 하던 프로세스는 큰 단계에 배치되지만, 이후 프로세스의 성격이 입출력 위주로 바뀐다면 점점 작은 단계로 배치될 수 있다.

## 병행 프로세스

### 병행 프로세스의 개념

#### 병행성(concurrency)

병행성은 여러 개의 프로세스 또는 쓰레드가 동시에 실행되는 시스템의 특성을 의미한다.

병행 프로세스가 실행되는 형태는 CPU 개수에 따라 차이가 있다.
하나의 CPU에서 병행 프로세스가 실행되는 경우에는 각 프로세스가 짧은 시간 간격으로 번갈아 실행되는 인터리빙 형식으로 실행된다.
정확히 한 순간에는 하나의 프로세스가 실행되지만, 전체적으로 보면 어러 프로세스가 동시에 실행되는 병행성을 보인다.

여러개의 CPU에서 병행 프로세스가 실행되는 경우에는 각 CPU에서 온전히 실행되어 병렬 처리 형식으로 실행된다.

여러개의 CPU에서 병행 프로세스가 실행되는 경우에도 메모리 구조에 따라 차이가 있다.

강결합(tightly coupled) 멀티 프로세서 시스템에서는 여러 CPU간에 하나의 기억장치를 공유하며 하나의 운영체제가 모든 CPU와 시스템 하드웨어를 제어한다.
강결합 시스템에는 master/slave 환경이나 Symmetric Multiprocessing이 해당된다.

약결합(loosely coupled) 멀티 프로세서 시스템에서는 2개 이상의 독립된 컴퓨터 시스템을 통신선을 통하여 연결한다.
각 시스템안 자신의 운영체제와 기억장치를 가지고 있으며 독립적으로 운영되고 필요할 때 통신을 한다.
시스템간의 통신은 메시지 전달이나 원격 프로시져 호출방식(remote procedure calls)을 사용한다.
약결합 시스템에는 클러스터 구조가 해당한다.

#### 단일 프로세스 내의 병행성

##### 우선순위 그래프

우선순위 그래프란 각 정점이 개개의 문장에 대응하는 사이클이 없는 방향 그래프이다.

```text
S1: a := x + y;
S2: b := z + 1;
S3: c := a + b;
s4: write(c);
```

위와 같은 경우

1. S3은 S1과 S2가 완료된 후에 실행될 수 있다.
2. S4는 S3이 완료된 후에 실행될 수 있다.
3. 따라서 S1과 S2는 동시에 실행될 수 있다.

##### Fork/Join 구조

fork {label} 명령어는 프로그램 내에서 2개의 병행 수행을 만들어 낸다.
하나는 label이 붙여진 문장에서 수행을 시작하고 다른 하나는 fork 명령어 다음 문장을 계속 수행한다.

join 명령어는 병행하는 2개의 연산을 하나로 재결합시키는 방법을 제공하며 2개의 연산은 서로 결합되도록 요청해야 한다.
3개의 연산이 결합될 경우에는 join을 실행하는 처음의 2개가 종료되어도 세 번째 연산은 계속되어야 한다.
마지막 하나를 제외하고 나머지는 모두 종료시킬 수 있도록 결합될 연산의 수를 알아야 한다.
따라서 join 명령어는 결합할 join의 수를 알아내는 매개변수를 갖는다.

fork/join 구조는 다중 쓰레드 프로그래밍을 할 때 주로 이용된다.

##### 병행문

1개의 프로세스가 여러 가닥의 병렬 프로세스로 분할되었다가 다시 한 가닥의 프로세스로 결합하는 것을 나타내기위해서 병행문을 사용한다.

`parbegin S1; S2; ... Sn; parend`

Si는 단일 문장이고 parbegin고 parend 사이에 있는 모든 문장은 병행하여 수행될 수 있다.

#### 프로세스 간의 병행성

프로세스간 병행성에서 상호 협력하는 경우를 비동기적(asynchronous)이라고 하며 때때로 자원을 공유하므로 복잡하다.

비동기 병행 프로세스는 어떤 프로세스가 실행중인 다른 프로세스에 영향을 주는 유기적 프로세스가 된다.
이로 인하여 동기화 문제가 발생할 수 있다.

### 동기화와 임계영역

프로세스 동기화는 2개 이상의 프로세스에 대한 처리순서를 결정하는 것을 말한다.
동시에 사용할 수 없는 공유자원이 있는 경우 프로세스 동기화 성공여부는
하나의 자원이 사용되는 동안에 다른 프로세스에서는 사용 불가능하게 만드는 운영체제에 달려있다.

프로그램에서 각 프로세스는 임계영역(critical section)이라 불리는 코드 세그먼트를 갖는데,
이 세그먼트에서 프로세스는 공용변수를 읽고, 테이블을 갱신하고, 파일에 쓰는 등의 일을 한다.

시스템의 가장 중요한 특징은 하나의 프로세스가 임계영역에서 수행 중일 때
다른 어떠한 프로세스도 이 임계영역에서 수행될 수 없다는 것이다.

임계영역을 갖는 프로세스의 일반적 구조는 다음과 같다.

- 진입영역: 각 프로세스는 그 임계 영역에 들어갈 수 있는지의 여부를 미리 요청
- 해제영역: 임계영역의 수행을 마치고 다음에 진입할 프로세스를 선택함
- 잔류영역: 임계영역을 마치고 나와서 나머지 작업을 수행

임계 영역 문제의 해결에 있어서는 다음의 세 가지 요구가 만족되어야 한다.

1. 상호배제: 프로세스 Pi가 임계영역에서 수행 중일 때 다른 어떤 프로세스도 임계영역에서 수행될 수 없다.
2. 진행: 임계영역에서 수행되는 프로세스가 없고 여러 프로세스가 임계영역에 들어오고자 할 때, 그중에서 다음에 임계영역에서 실행할 대상을 결정해야 하며 결정은 무한정 미루어질 수 없다.
3. 제한된 대기: 한 프로세스가 임계영역에 대한 요청 후 부터 요청이 수락되기 까지의 기간 내에 다른 프로세스가 임계영역을 수행할 수 있는 횟수에는 제한이 있어야 한다.

동기화는 때때로 절대영역에서 일할 수 있는 프로세스에 앞서 'lock-and-key'를 실행한다.
일단 키를 가지면 절대영역에 들어간 프로세스가 일을 마치고 키를 반환할 때까지 모든 다른 프로세스는 잠기게 된다.

이런 구조는 동시에 행위를 취해야 하며 단일 기계 사이클에서 이루어져야 하는데, 수행방법에는 여러 종류가 있다.
Test and Set과 세마포어(semaphore)가 이러한 수행방법이다.

#### Test-and-Set

상호배제의 하드웨어적 해결방법으로 분리가 불가능한 단일 기계 명령어로서, 간단히 'TS'라고 한다.
단일 기계사이클로 동작하여 프로세서는 lock을 사용할 수 있는지 여부를 확인한 후 사용할 수 있으면 '사용할 수 없음'으로 세팅한다.

Test-and-Set은 두 가지의 결점을 가지고 있다.

첫째, 많은 프로세스가 절대 영역에 들어가기를 원할 때 starvation이 발생하는데, 프로세스가 임의접근을 시도하기 때문이다.
FCFS 정책이 정해지지 않는다면 어떤 프로세스가 실행되지 못할 수도 있다.

둘째, 대기 프로세스는 비생산적이고 자원만을 소비하는 busy waiting이 발생한다.

#### 세마포어

세마포어(Semaphore)는 에츠허르 데이크스트라가 고안한, 두 개의 원자적 함수로 조작되는 정수 변수로서
멀티프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법으로 사용된다.

세마포어의 가장 잘 알려진 예는 철도에서 열차의 진행 가능 여부를 나타내는 신호기이다.
신호기가 올라가면 장애물이 있다는 표시로 열차는 신호기가 내려갈 때까지 기다려야 한다.

세마포어 s는 정수값을 가지며 두 표준 단위연산 P(검사)와 V(연산)에 의해서만 접근되는 정수형 공용변수이다.

```text
P(s):
  if (s > 0) then
    s :- s-1;
  else
    현재프로세스 대기;

V(s):
  if (1개 이상의 프로세스가 대기중) then
    그중 1개의 프로세스만 진행;
  else
    s := s+1;
```

### 프로세스의 상호협력

#### 생상자/소비자(producers/consumers) 문제

생산자/소비자 문제는 유한 버퍼(bounded buffer) 문제라고도 한다.

고정된 크기의 버퍼를 사이에 두고 버퍼가 비어있다면 소비자가 기다리게 되고 버퍼가 가득 차면 생산자가 기다리게 된다.
이는 상호배제(한 순간에 한 프로세스만이 버퍼를 사용해야 하고)와 동기화(생산이 이루어져야 소비가 가능하고, 버퍼 용량 이상을 생산하면 안됨)가 해결되어야 하며, 세마포어를 이용하여 구현한다.

#### 판독기/기록기 문제

대이터 객체는 여러 병행 프로세스 간에 공유될 수 있다.
프로세스 중의 일부는 다른 것이 공유객체의 내용을 읽기 원할 때, 공유 객체의 갱신(읽기/쓰기)을 원할 수 있다.
읽고자 하는 프로세스는 판독기(reader), 쓰고자 하는 프로세는 기록기(writer)라고 구분한다.

기록기와 또다른 프로세스가 동시에 공유객체에 접근한다면 병행성 조건을 침해하게 된다.
따라서 기록기가 공유객체에 대해 배타적으로 접근하도록 해야 한다.

제1 판독기/기록기 문제는, 어떠한 판독기도 기록기가 대기중이라는 이유로 다른 판독기가 끝나기를 기다리지 않는다.
제2 판독기/기록기 문제는, 일단 기록기가 준비되었다면 기록을 가능한 빨리 수행할 수 있도록 하는 것이다.
두 문제에 대한 모든 해답이 starvation을 발생시킬 수 있음을 주의해야 한다.

### 프로세스 간의 통신

동기화 문제를 큰 각도로 보면 협력하려는 프로세스 간의 통신을 허락하는 문제로도 볼 수 있다.

#### 공유 기억장치 기법

통신하는 프로세스 간에 변수를 공유하도록 하여 프로세스가 공유변수를 이용하여 정보를 교환하도록 하는 것으로, 유한 버퍼가 한 예이다.

#### 메시지 시스템 기법

프로세스 P와 Q가 통신하기를 원한다면 서로 메시지를 주고받아야 한다.
이를 위한 통신링크는 여러 방법으로 구현될 수 있다.

##### 직접 통신

직접 통신 기법에서는 메시지를 주고받기 원하는 각각의 프로세스는 수신자나 전송자의 이름을 명시해야 한다.

1. 통신을 원하는 모든 프로세스의 쌍 사이에 링크가 자동으로 설정된다.
2. 프로세스는 통신하기 위하여 서로 상대방의 신원을 알아야 한다.
3. 하나의 링크는 두 프로세스 사이에만 연관된다.
4. 각 통신 프로세스 쌍 사이에는 정확히 하나의 링크가 존재한다.
5. 링크는 양방향이다.

직접 통신의 단점은 프로세스의 이름을 바꾸려면 다른 모든 프로세스의 정의를 조사해야 한다는 점이다.

##### 간접 통신

간접 통신을 통해 우편함으로부터 메시지를 보내거나 받을 수 있다.
우편함은 프로세스에 의해 메시지가 넣어지고 빠지는 객체로 취급할 수 있다.
각 우편함은 유일한 이름을 갖고 프로세스는 서로 다른 우편함에 의하여 다른 프로세스와 통신할 수 있다.

1. 공유 우편함이 있는 경우에만 프로세스 쌍 사이에 링크가 설정된다.
2. 한 링크는 2개 이상의 프로세스들과 연관될 수 있다.
3. 각 통신 프로세스 쌍 사이에는 몇 개의 다른 링크가 있을 수 있으며, 각각은 서로 다른 우편함과 교신한다.
4. 링크는 단방향이거나 양방향일 수 있다.

우편함은 프로세스나 시스템에 소속될 수 있다.
우편함이 프로세스에 소속될 때는 우편함의 소유자와 사용자를 구별한다.
우편함을 소유하고 있는 프로세스가 종료되면 우편함은 없어진다.
따라서 우편함에 메시지를 송신하는 모든 프로세스에게 더 이상 우편함이 존재하지 않는다는 것을 알려주어야 한다.

운영체제가 소유하는 우편함은 스스로 존재힌다. 독립적이며 어떤 프로세스에 속하지 않는다.

##### 링크의 용량

링크는 임시로 저장되는 메시지의 수를 결정하는 용량을 갖는다.
이런 특성은 링크에 붙여지는 메시지의 큐로써 생각될 수 있다.

1. 0용량: 링크는 어떠한 메시지도 가질수 없으므로 송신자는 수신자가 메시지를 수신할 때 까지 기다려야한다.
2. 제한된용량: 큐가 차있지 않다면 세로운 메시지는 큐에 들어간다. 링크가 꽉차면 송신자는 큐에 공간이 생길때까지 기다려야 한다.
3. 무제한용량: 송신자는 기다리는 경우가 없다.

0용량이 아닌경우 송신자는 메시지 전달여부를 알기 위하여 수신자와 통신을 해야 한다. 이런경우 프로세스는 비동기적으로 통신한다고 한다.

##### 예외조건

메시지 시스템은 분산환경에 유용한데 이런경우 통신과 처리의 오류가 발생할 확률은 단일 시스템 보다 높다.

시스템이 메시지 처리 방법에서 취급해야 할 예외조건들

1. 프로세스 종료: 송신/수신 프로세스는 메시지가 처리되기 전에 긑날 수 있다.
2. 메시지 상실: 프로세스간 메시지 전송 중 하드웨어나 통신장애로 상실 될 수 있다.
3. 메시지 혼합: 메시지는 배달되는 도중 뒤섞일 수 있다(잡음...), 오류 탐지를 사용한다.(checksum...)

## 교착상태

### 교착상태의 개념

프로세스는 필요한 자원이 있으면 요구하는 과정을 통해 자원을 획득한 후 사용한다.
그리고 사용이 끝나면 획득했던 자원을 반납한다. 만약 요구 과정에서 가용 자원이 없으면 대기하게 된다.

교착상태(Deadlock)란 2개 이상의 프로세스가 서로 상대방의 작업이 끝나기만을 기다리고 있어서 결과적으로 어느 쪽도 완료되지 못하는 상태를 의미한다.

예를 들어, 프로세스 1은 자원 1을 획득한 상태에서 자원 2를 요구하고 프로세스 2는 자원 2를 획득한 상태에서 자원 1을 요구한다면,
두 프로세스는 서로 상대방이 작업을 끝내고 자원을 반납하기만을 기다리는 교착상태가 된다.

교착상태와 기아상태는 다르다.
교착상태는 관련된 모든 프로세스가 무한히 대기상태인 것을 의미하고,
기아상태는 관련된 프로세스의 일부가 지속적으로 대기상태인 것을 의미한다.

### 교착상태의 특성

#### 교착상태의 필요조건

다음의 네 가지 조건을 동시에 만족하는 경우에 발생한다

1. 상호배제: 필요로 하는 자원을 다른 프로세스가 점유하고 있으면 반드시 대기해야 한다
2. 점유 대기: 프로세스가 이미 다른 자원을 할당받아 배타적으로 점유하고 있는 상황에서 다른 프로세스가 점유하고 있는 자원이 해제되기를 기다리는 상황
3. 비선점: 프로세스에 할당된 자원은 그 프로세스가 사용을 마치고 스스로 반환하기 전에 제거되지 않음
4. 환형 대기: 프로세스의 자원 점유 및 점유된 자원의 요구 관계가 환형을 이루며 대기하는 조건

#### 자원할당 그래프

resource allocation graph: G = (V, E)

- V: 정점의 집합, 두 종류의 정점이 있고 V = P ∪ R
- P: P1 ... Pn: n개의 프로세스
- R: R1 ... Rm: m개의 자원
- E: 방향이 있는 간선의 집합, E = Q ∪ S
  - Q = {(Pi, Rj)}: 프로세스 Pi가 자원 Rj를 요구(요구간선)
  - S = {(Rj, Pi)}: 자원 Rj가 프로세스 Pi에 할당됨(할당간선)

교착상태가 그래프로 표현되는 상태

- 상호배제: 하나의 단위자원은 하나의 프로세스에게만 할당하는 할당간선
- 점유 대기: 할당간선
- 비선점: 가용한 단위자원이 없는 경우 요구간선
- 환형대기: cycle로 표현

### 교착상태 처리

교착 상태 처리를 위한 방법은 주로 세 가지가 있다.

#### 방지(Prevention)

교착상태는 반드시 네 가지의 필요조건을 수반하므로,
이들 중 어느하나라도 발생할 수 없게 한다면 교착상태의 발생을 방지할 수 있다.

##### 상호 배제 조건의 제거

공유할 수 있는 자원(읽기전용 ...)은 상호배제를 할 필요가 없으므로 교착상태를 유발하지 않음.
하지만 공유할 수 없는 자원은 반드시 상호배제를 따라야하므로 제거 불가조건이 된다.

##### 점유 대기 조건의 제거

점유 대기 조건이 발생하지 않으려면 프로세스가 자원을 요청할 때 그 프로세스는 어떠한 자원도 할당받지 않은 상태여야 한다.

- 프로세스가 수행을 시작하기 전에 필요한 모든 자원을 한꺼번에 요구하여 할당받는다
  - 프로세스에 대한 자원을 요구하는 시스템 호출을 모든 여타의 시스템 호출보다 선행시킴으로 구현할 수 있다
  - 많은 자원들이 할당되지만 오랫동안 사용되지 않아 자원 이용률이 매우 낮을 수 있다

- 자원을 부분적으로 요청하여 할당받을 수 있도록 하되, 자원을 추가로 요청할 때에는 이전에 가지고 있던 자원을 반드시 모두 해제한 후 할당받음
  - 빈번히 사용되는 자원의 경우 다른 프로세스에 할당되어 있을 수 있어 기아상태(starvation)가 발생할 수 있다

##### 비선점 조건의 제거

- 자원을 점유하고 있는 프로세스가 다른 자원을 요청했으나 그 자원을 즉시 사용할 수 없는 상황이라면 점유하고 있던 자원을 해제하는 것
  - 해제한 자원을 포함하여 모든 자원이 사용 가능해지면 프로세스를 재개한다

- 만일 프로세스가 어떤 자원을 요청하면 먼저 그 자원의 가용 여부를 조사
  - 가용상태이면 할당하고 가용하지 않은 경우이면 그 자원이 다른 자원을 기다리며 대기 중 프로세스에 할당되어 있는지를 조사한다
  - 대기 중이라면 대기상태인 프로세스로부터 자원을 선점하여 요청한 프로세스에 할당해준다
  - 자원이 가용상태가 아니거나 실행 중인 프로세스에 의해 소유되고 있으면 요청한 프로세스는 반드시 대기해야 한다
  - 앞서 대기상태에서 자신의 자원이 강제 해제된 프로세스는 기다리던 자원을 할당받았을 대 강제 해제된 자원을 다시 요청하여 할당받은 후 작업을 수행한다

이러한 방법들은 CPU의 레지스터나 메모리와 같이 상태를 쉽게 보관하고 복구할 수 있는 자원에만 적용 가능하다.

##### 환형 대기 조건의 제거

m개의 자원 R1 ... Rm에 대해 각각을 서로 다른 자연수로 지정하는 함수 f를 정의한다.
함수 f는 `Ri != Rj`이면 `f(Ri) != f(Rj)`를 만족하는 단사함수이다.

- 프로세스는 자원을 일렬번호 기준으로 항상 오름차순으로 요청하도록 한다
  - 자원 `Ri`를 점유하고 있는 경우 반드시 `f(Ri) < f(Rj)`인 경우에만 `Rj`를 요청할 수 있다
- 프로세스가 자원 `Rj`를 요구할 때마다 `f(Ri) <= f(Rj)`인 자원 `Ri`는 모두 해제하도록 한다

만약 `{P1 ... Pn}`의 프로세스에 환형 대기가 존재한다고 가정하자.
프로세스 `Pi`는 `Pi+1`이 지닌 `Ri`를 기다리고 있으며 `Pn`은 `P1`이 지닌 `Rn`을 기다리고 있기 때문에, 모든 i에 대하여 `f(Ri) < f(Ri+1)`이다.

이 경우 `f(R1) < ... < f(Rn) < f(R1)`을 의미하게 되고 `f(R1) < f(R1)`이 되므로 환형대기는 발생할 수 없음을 증명할 수 있다.

여기에 사용되는 함수 `f`의 정의는 전체 시스템에 큰 영향을 미치므로 실제로 자원이 사용되는 순서를 감안하여 정의해야 한다.

#### 회피(Avoidance)

> 회피: 프로세스의 자원 사용에 대한 사전 정보를 활용하여 교착상태가 발생하지 않는 상태에 머물도록 하는 방법

자원 사용에 대한 사전 정보로는 현재 할당된 자원, 가용상태의 자원, 프로세스들의 최대 요구량이 활용된다.

- 안전상태(safe state): 교착 상태를 회피하면서 각 프로세스에게 그들의 최대 요구량까지 빠짐없이 자원을 할당할 수 있는 상태

- 시스템이 안전상태에 있다는 말은 안전 순서열(safe sequence)이 존재하는 것
  - 안전 순서열이란 각 `Pi`는 `Pi`가 추가로 요구할 수 있는 자원 소요량이 현재 가용상태이거나
  - 혹은 현재 가용인 자원에 `j < i`인 `Pj`에 할당된 자원까지 포함하여 할당이 가능한 경우

- 불안전상태(unsafe state): 안전 순서열이 존재하지 않는 경우
  - 불안전상태에서는 할당과정에 따라서 교착상태가 될 수도 있다

##### 각 유형의 단위자원이 여러 개일 경우

> 은행원 알고리즘(banker's algorithm): 시스템이 자원을 요청받으면 그 자원을 할당해 주고 난 후의 상태를 여러 데이터를 이용하여 계산해서 그것이 안전상태인지를 확인하고 안전상태가 보장되는 경우에만 할당한다

- AVAIL(가용자원): `AVAIL(j) = k`란 `Rj`유형의 자원중 `k`개의 단위자원이 가용상태임을 뜻한다
- MAX(최대요구): `MAX(i, j) = k`란 프로세스 `Pi`는 `Ri`유형의 자원을 최대 `k`개까지 요구할 수 있음을 뜻한다
- ALLOC(할당자원): `ALLOC(i, j) = k`란 `Rj`유형의 자원 중 `k`개가 프로세스 `Pi`에 할당되어 있음을 뜻한다
- NEED(추가요구): `NEED(i, j) = MAX(i, j) - ALLOC(i, j)`

`REQi(j) = k`란 `Pi`가 `Rj`유형의 자원 `k`개를 요구함을 뜻한다. `Pi`가 자원을 요청할 때 다음과정을 거친다

- `REQi <= NEEDi`가 거짓이면 이는 오류임(프로세스가 자신의 최대 요구량 이상 요청)
- `REQi <= AVAIL`이 거짓이면 `Pi`는 대기상태가 된다
- `REQi <= AVAIL`이면
  - 시스템은 다음과 같이 할당 후와 같은 상태를 만든다
  - `AVAIL <- AVAIL - REQi`
  - `ALLOCi <- ALLOCi + REQi`
  - `NEEDi <- NEEDi - REQi`
  - 위의 새로운 상태가 안전상태인지를 조사한다(안전 알고리즘이용)
  - 안전상태이면 `REQi`를 할당하고 그렇지 않으면 프로세스를 대기상태로 만들고 데이터 구조를 이전으로 복구한다

다음과 같은 **안전 알고리즘**으로 안전상태인지를 조사한다

- (1)길이가 각각 `m`, `n`인 벡터 `WORK`와 `FINISH`를 초기화한다
  - `WORK <- AVAIL`
  - `FINISH(i) <- false, i= 1, 2 ... n`
- (2)`FINISH(i) = false`이고 `NEEDi <= WORK`인 `i`를 찾는다
  - 해당 `i`가 없으면 (4)를 실행
- (3)`WORK <- WORK + ALLOCi`
  - `FINISH(i) <- true`
  - (2)를 실행
- (4)만일 모든 `i`에 대하여 `FINISH(i) = true`이면 시스템은 안전상태이다

##### 각 유형의 단위자원이 하나밖에 없을 경우

은행원 알고리즘은 안전상태 여부를 결정하기 위해 매번 `m*n^2`의 연산이 필요하다.
따라서 각 유형의 단위자원이 하나씩만 있는 경우에 적용할 수 있는 보다 효율적인 알고리즘을 살펴보자.

- 자원할당 그래프에서 원래의 요구간선과 할당간선 외에 선언간선을 추가한다
- 선언간선 (Pi, Rj)는 앞으로 프로세스 Pi가 자원 Rj를 요구하게 될 것임을 나타낸다
- 요구간선과 동일한 방향성을 지니나 구분하여 표시한다
- Pi가 Rj를 요구할 때 선언간선(Pi, Rj)는 요구간선으로 변환된다
- 자원 Rj가 Pi에 의해 해제될 때 할당간선 (Pi, Rj)는 선언간선 (Pi, Rj)로 변환된다
- 프로세스는 수행을 시작하기 전에 필요한 자원을 시스템에 알려 그래프에 선언간선을 추가해 놓는다

프로세스 Pi가 자원 Rj를 요구할 때 요구간선 (Pi, Rj)를 할당간선 (Rj, Pi)로 변환하여도 사이클이 발생되지 않는 경우에만 허용된다.
사이클 탐지는 `n^2`의 연산으로 가능하다.

사이클이 발생하면 Pi는 대기상태로 두고 간선을 변환시키지 않는다.

#### 탐지 및 복구(Detection and Recovery)

탐지 및 복구는 방지나 회피와 달리 일단 교착상태가 발생하면 이를 탐지하고 교착상태를 해결하는 방법이다.

##### 탐지

시스템이 교착상태에 있는지 여부를 탐지하기 위해 Shoshani & Coffman의 알고리즘을 이용할 수 있다.

- (1)길이가 각각 n, n인 벡터 WORK와 FINISH를 초기화한다
  - `WORK <- AVAIL`
  - `ALLOCi != 0`이면 `FINISH(i) <- false`
  - 그렇지 않으면 `FINISH(i) <- true, i = 1 ... n`
- (2)`FINISH(i) = false`이고 `REQi <= WORK`인 `i`를 찾는다
  - 그런 I가 없으면 goto (4)
- (3)`WORK <- WORK + ALLOCi`
  - `FINISH(i) <- true`
  - goto (2)
- (4)만일 어떤 `i`에 대해 `FINISH(i) = false`이면 시스템(`Pi`)은 교착상태이다

##### 복구

교착상태가 탐지되고 나면 복구해야 한다.
복구 방법으로는 교착상태의 프로세스를 종료시키거나 자원을 회수할 수 있다.

모든 교착상태 프로세스를 종료시키거나, 사이클이 제거될 때까지 프로세스를 하나씩 종료시킬 수 있다.

전체 종료는 교착상태를 확실히 해소할 수 있지만, 종료된 프로세스들에 대한 복원 비용이 많이 필요하다.

부분 종료는 종료할 프로세스를 선택하기위해 프로세스의 우선순위, 진척도, 사용된 자원의 유형과 양등 다양한 요소를 고려해야 한다.
또한 프로세스를 종료한 이후 교착상태를 재확인 하기 위한 오버헤드가 있다.

자원을 회수하기 위해서는 프로세스로부터 자원을 단계적으로 선점하여 이 자원들을 교착상태 사이클이 없어질 때까지 다른 프로세스들에 할당한다.

- 희생자 선택
  - 프로세스가 종료상태에 있게되면 비용을 최소화하기 위해 선점순서를 결정해야 한다
  - 비용요소는 교착상태 프로세스가 소유하고 있는 자원의 수와 교착상태에 있는 프로세스가 실행하는동안 소모하는 시간을 포함한다

- 복귀
  - 프로세스로부터 자원을 선점한다면, 그 프로세스를 어떤 상태로 놓을 것인지를 결정해야 한다
  - 가장 간단한 방법은 total rollback으로 프로세스를 포기하고 처음부터 재시작 하는 것
  - 그러나 복구를 시키되 꼭 필요한 상태까지만 복귀시키는 것이 효과적인 방법일 것이다
  - 그러한 방법을 위해서는 수행 중인 모든 프로세스에 대한 상세정보를 기억하고 있어야 한다

- 기아상태
  - 희생자 선택은 주로 비용요소에 기초를 두는 시스템에서는 동일한 프로세스가 매번 선택될 수 있다
  - 결과적으로 그 프로세스는 계속하여 작업을 완료하지 못할 수 있다
  - 이러한 상황을 기아상태라고 하고, 비용요소에 rollback 횟수를 포함할 필요가 있다

#### 복합적 접근방법

방지, 회피, 탐지 및 복구와 같은 방법들을 복합적으로 사용하면 보다 적절한 처리가 가능하다.

한 가지 방안은 자원을 유형에 따라 계층적으로 분류하여 최적 기법을 선택 적용하는 것이다.
또한 각 계층에 대하여 자원순서를 부여하여 전체 시스템의 교착상태를 피할 수 있다.

교착상태를 처리하기 위해 각 유형에 따라 다음과 같이 적절한 방법을 적용할 수 있다.

- 내부자원에 대해서는 수행되면서 기다리는 요청 중에서 선택할 필요가 없으므로 자원에 순서를 주는 교착상태 방지가 적합
- CPU와 메모리에 대해서는 작업은 교체가 가능하므로 선점을 통한 교착상태 방지가 적합
- 작업용 자원에 대해서는 자원에 대한 정보를 작업제어 카드로 얻을 수 있으므로 교착상태 회피가 사용될 수 있다
- 교체 가능 공간에 대해서 기억장치의 최대 사용량은 이랍ㄴ적으로 미리 알 수 있으므로 사전 할당이 이용될 수 있다

## 메모리 관리

프로세스가 실행상태에서 하는 동작은 프로그램 카운터(PC)를 참조하여 수행될 명령을 읽어 와서 CPU의 해당명령을 수행하는 것인데,
이때 프로그램 카운터가 가리키는 주소는 메모리상의 특정위치이다.

기억장치는 레지스터 / 캐시 / 메모리 / 보조기억장치 순으로 용량은 커지고 속도는 느려지므로 효율적인 관리가 필요하다.

### 단일 프로그래밍 환경

초기의 시스템은 오직 하나의 프로세스만 메모리를 사용하였기 때문에 나머지 사용자는 기다려야 했다.
이 때 프로세스는 하나의 연속된 블록으로 메모리에 할당되는 방식이었다.

이 경우 시스템 자원을 효율적으로 사용할 수 없다.

### 다중 프로그래밍 환경

다중 프로그래밍이란 여러 개의 프로세스가 메모리에 동시에 적재되는 것으로,
현재 실행 중인 프로세스가 입출력 대기를 해야 하면 실행을 기다리고 있는 다른 프로세스에 CPU를 할당할 수 있다.

#### 메모리 분할

하나의 메모리 분할에 하나의 프로세스가 적재되는 방식으로 고정 분할 방식과 동적 분할 방식으로 나뉜다.

##### 고정 분할

메모리를 여러 개의 고정된 크기의 영역으로 분할하는 방식이다.

분할된 영역에서 프로세스를 배치하는 방법

- 각 분할 영역마다 큐를 두고 큐에 들어온 프로세스는 해당 분할 영역에만 적재
  - 구현은 용이하나 빈 분할이 있어도 다른 큐의 프로세스는 적재할 수 없음

- 메모리 전체에 하나의 큐만 두고 비어있는 분할에 적재한다
  - 기억장치의 낭비를 줄이지만 재배치 가능 번역기와 로더는 절대 번역기보다 복잡하다

##### 동적 분할

메모리의 분할 경계가 고정되지 않고 각 프로세스에 필요한 만큼의 메모리만을 할당하는 방식이다

필요한 시점에 필요한 만큼의 메모리만 할당받기 때문에 고정분할에서 발생하는 내부 단편화 문제는 없으나,
메모리의 할당과 반복이 반복됨에 따라 작은 공백이 메모리 공간 여러곳에 생기는 외부 단편화 문제가 발생한다.

외부 단편화를 해결하는 방법으로 통합(coalescing)과 집약(compaction)이 있다.

- 통합
  - 하나의 프로세스가 끝났을 때
  - 그 프로세스가 차지하고 있는 메모리 영역이 다른 비어있는 메모리와 인접해 있는 지 조사
  - 인접해 있다면 빈 공간 리스트에 새로운 공백이나 기존의 공백과 합쳐 하나의 공백으로 만드는 것

- 집약: 내의 공백을 하나로 모으는 작업

#### 메모리 보호

연속 메모리 할당 방식에서는 프로세스가 사용할 수 있는 주소 범위를
하한/상한-상한/하한 레지스터 쌍으로 제한함으로써 다른 할당영역을 침범하지 않게 한다.

### 메모리 배치 기법

#### 최초 적합 (first-fit)

빈 공간 리스트를 메모리의 주소순으로 유지하며 프로세스가 적재될 수 있는 빈 공간 중에서 가장 먼저 발견되는 곳을 할당한다

#### 후속 적합 (next-fit)

이전에 탐색이 끝난 다음 부분부터 시작하여 사용이 가능한 빈 공간 중에서 가장 먼저 발견되는 것을 할당한다.

#### 최적 적합 (best-fit)

필요한 공간을 제공할 수 있는 빈 공간 중 가장 작은 곳을 선택하여 할당한다

#### 최악 적합 (worst-fit)

필요한 공간을 제공할 수 있는 빈 공간 중 가장 큰 곳을 선택하여 할당한다.
이는 작은 자투리 공간 발생을 최소화 하기 위한 방법이다.

## 가상 메모리

### 가상 메모리 개념

가상 메모리(virtual memory)는 컴퓨터 시스템의 메모리보다 더 큰 기억 공간이 필요한 프로세스를 실행할 수 있게 하는 방법이다.

가상 메모리 개념의 핵심은 실행중인 프로세스에 의해 참조되는 주소를 메모리에서 사용하는 주소와 분리하는 것이다.
그리고 현재 필요한 일부만 메모리에 적재함으로써 프로세스 수행이 가능하도록 한다.
이때 실행 프로세스가 참조하는 주소를 가상주소(virtual address)라 하고,
실제 메모리에서 사용하는 주소를 실주소 또는 물리적 주소(real/physical address)라고 한다.

프로세스는 가상주소만을 참조하지만 프로세스가 실행되면 가상주소는 실주소로 변환되어야 하는데, 이 변환과정을 mapping이라고 하며 변환함수로 표시된다.
운영체제에서 변환작업을 수행하므로 사용자는 실제로 관여하지는 않는다.

프로세스 실행 중 가상주소를 실주소로 바꾸는 절차를 동적 주소 변환(Dynamic Address Translation)이라고 한다.

### 블록 단위 주소 변환

동적 주소 변환 방법은 가상 메모리에서 위치가 현재 메모리의 어디에 위치하는지를 나타내는 주소 변환 사상표(address translation mapping table)를 유지해야 한다.

주소 변환이 가상주소 내의 각 항목별(byte, word...)로 이루어진다면, 변환에 필요한 정보량이 많아져서 효율적인 메모리사용이 어렵다.
따라서 정보를 블록 단위로 분류하여 각 블록이 주기억장치의 어디에 위치하는지만 관리한다.

블록 사상 시스템의 주소는 두 부분으로 구성된다. 항목이 들어있는 블록과 그 블록의 시작 부분으로 부터 항목까지위 변위(displacement)를 지정한다.

블록이 커짐에 따라 사상정보를 저장할 메모리 크기가 작아진다.
블록을 크게하면 사상정보를 저장할 기억장치 크기는 줄일 수 있으나,
큰 블록을 메모리에서 보조기억장치로 전송하는 시간을 길게하며 메모리 소모를 늘리고 메모리를 공유할 수 있는 프로세스 수를 제한한다.

- 블록 크기가 동일할 때 블록을 페이지(page)라 부르고 이런 가상메모리 구성을 페이징(paging)기법이라 한다
- 블록 크기가 다를 때는 세그먼트(segment)라 하고 이런 가상메모리 구성을 세그먼테이션(segmentation)기법이라고 한다
- 두 기법을 결합하여 고정된 크기의 페이지로 이루어진 다양한 세그먼트를 구현할 수도 있다

#### 페이징 기법

페이징 기법은 가상 메모리를 고정된 블록(= 페이지) 단위로 나누어 관리하는 기법이다.

> i.e. 가상 메모리상의 위치가 3번 페이지 내부 시작점으로 부터 8byte 떨어져 있다면 `v = (3, 8)`

프로세스가 실행을 위해 특정 페이지를 참조하려면 해당 페이지는 메모리에 위치해야 한다.
이를 위해 메모리 영역도 가상 메모리와 동일하게 고정된 크기의 블록으로 나누고, 각 블록을 페이지 프레임(page frame)이라고 부른다.

페이지는 비어있는 페이지 프레임에 적재하면 된다.

가상주소를 메모리에 적재한 후에 찾을 수 있도록 실주소로 동적변환을 해야 한다. 이를 위해 mapping table을 사용한다.
테이블에는 가상주소의 페이지 번호에 대응하는 실주소의 페이지 프레임 번호가 있다.
또한 페이지가 현재 메모리에 존재하는지 여부를 나타내는 비트값과, 존재 하지 않는경우 보조기억장치내의 위치정보도 함께 저장되어 있다.

mapping table을 직접 사용하여 동적 주소변환을 하는 것을 직접 사상이라하며,
연관기억장치에 저장한 연관 사상표를 사용하여 동적 주소변환을 하는 방식을 연관 사상이라 한다.
연관기억장치는 저장된 값을 이용하여 데이터를 액세스하는 고속 메모리 장치이다.

일반적으로는 두 방법을 함께 사용한다.
연관 사상표에는 가장 최근에 참조한 페이지 항목만 보관하고 나머지는 페이지 사상표를 사용하여 연관 사상표에 없는 항목은 직접 사상 기법을 사용한다.

페이징 기법에서 프로세스 사이의 메모리 보호는 페이지 단위로 이루어진다.
메모리도 동일 크기의 페이지 프레임으로 나누어져서 사용되므로 외부 단편화는 발생하지 않는다. 대신 페이지 내부 단편화는 발생할 수 있다.

#### 세그먼테이션 기법

세그먼테이션 기법에서 가상주소는 세그먼트 번호와 세그먼트 시작위치로부터의 변위 쌍으로 이루어진다.

세그먼트를 메모리에 적재하려면 자신을 수용할 수 있을 만큼 충분히 크고 사용가능한 영역에 놓으면 된다.
세그먼테이션 기법의 위치 지정방법은 동적분할 다중 프로그래밍에서 흔히 사용되는 최초 적합(first-fit), 최적 적합(best-fit)등의 방법과 동일하다.

동적 주소 변환은 페이지 사상표과 유사한 세그먼트 사상표를 이용한다.
세그먼트 사상표는 가상주소의 세그먼트 번호에 대한 실주소에서의 시작위치가 저장되어 있다.
또한 해당 세그먼트가 현재 메모리에 존재하는지 여부를 나타내는 비트값과, 보조기억장치에서의 위치정보도 함께 저장되어 있다.
이러한 정보들은 세그먼트 overflow를 확인할 때 사용된다.

#### 페이징-세그먼테이션 혼용기법

페이징-세그먼테이션 혼용기법은 세그먼테이션 기법의 논리적 장점과 페이징 기법의 메모리 관리 장점을 동시에 활용하기 위함이다.

각 세그먼트를 다시 페이지 단위로 분리하고 메모리도 페이지 프레임으로 분할하여 하나의 페이지만 페이지프레임에 적재하는 방식이다.
가상주소는 세그먼트 번호, 세그먼트의 페이지번호, 항목이 위치하는 페이지내의 변위 세 순서쌍으로 표현된다.

### 페이지 호출기법

#### 요구 페이지 호출기법

요구 페이지 호출기법(demand page fetch strategy)이란 프로세스의 페이지 요구가 있을 때 요구 페이지를 메모리로 이동하는 것이다.

어느 페이지를 메모리에 옮길지 결정하는데 있어서 오버헤드를 최소화하고 실제로 메모리에 옮겨진 페이지는 모두 프로세스에 의해 실제로 참조되는 것이다.

#### 예상 페이지 호출 기법

예상 페이지 호출기법이란 현 시점에서 액세스 되고 있지 않지만 곧 사용될 것으로 예상되는 페이지를 미리 메모리에 옮겨놓는 방법이다.

만약 요구페이지 호출기법을 사용한다면 메모리는 첫 번째 페이지만 적재되므로 프로세스의 실행에 따라 페이지 부재(page fault)가 발생하여 성능이 저하된다.

### 페이지 교체기법

페이징 기법에서는 모든 페이지 프레임이 사용되고 있는 것이 일반적이다.
이 경우 운영체제는 매모리에 새로 적재되어야 할 페이지를 위해 교체 대상 페이지 프레임을 선택하여 그 내용을 보조기억장치에 보과한 후 새로운 페이지를 적재해야 한다.

최적의 페이지 교체를 위해서는 교체되어야 할 페이지가 이후 가장 오랫동안 사용되지 않으면 되고 이를 최적화 원칙이라 한다.

이론상 그런 것이고 대체적으로 좋은 결과를 내면서 시간 및 공간의 오버헤드가 적은 방법을 선택하는 것이 좋다.
또한 슈퍼바이저 코드 영역, 커널에 속하지 않은 보조기억장치 드라이버 영역, 입출력장치 데이터 버퍼영역 등 성능을 위해 교체가 일어나지 말아야할 페이지를 피해야 한다.

#### FIFO 페이지 교체

First-In FIrst-Out 페이지 교체기법에서는 각 페이지가 메모리에 적재될 때마다 그때의 시간을 기억한다.
페이지를 교체할 때는 메모리 내에 가장 오래 있었던 페이지를 교체한다.

FIFO 페이지 교체기법은 간단히 FIFO 큐로 구현할 수 있다.

그러나 메모리에 가장 오래 있었던 페이지가 앞으로도 계속 사용될 가능성이 있으므로 많이 쓰이는 페이지를 교체할 수도 있다.

또한 Belady anomaly가 발생할 수 있다.
이는 프로세스에 더 많은 수의 페이지 프레임을 할당할 경우 오히려 페이지 부재가 더 많이 발생하는 문제이다.

#### LRU 페이지 교체

Least Recently Used 페이지 교체기법은 가장 오랫동안 사용되지 않은 페이지를 선택하여 교체하는 전략이다.

LRU 페이지 교체기법은 두 가지 방식으로 구현가능하다.

첫 번째는 참조시간을 이용하여 각 페이지가 참조될 때마다 그때의 시간을 테이블에 기록하고, 교체가 필요한 경우 참조시간이 가장 오래된 페이지를 선택한다.

두 번째는 리스트를 이용하는 방법으로 메모리에 적재된 페이지 번호를 저장하는 리스트를 이용하고, 페이지를 액세스하면 해당 페이지 번호를 리스트의 선두로 옮긴다.
교체가 필요한 경우 리스트의 끝에 있는 페이지가 교체 대상으로 선택된다.

LRU 기법은 Belady anomaly가 발생하지 않고 많은경우 최적화 원칙에 근사한 선택을 할 수 있다.
그러나 경험적 판단이 맞지 않은 상황이 존재할 수도 있고, LRU는 막대한 오버헤드를 초래하여 많이 사용되는 기법은 아니다.

#### LFU 페이지 교체

LRU와 유사항 기법으로 각 페이지가 얼마나 많이 사용되었는지에 착안한 Least Frequently Used 페이지 교체기법이다.
여기서는 참조된 횟수가 가장 적은 페이지가 교체된다.

LFU도 최적화 원칙에서 벗어날 수 있다.
예를 들어, 가장 드물게 이용된 페이지가 가장 최근 메모리로 옮겨진 페이지일 수도 있다.
또한 LRU와 마찬가지로 오버헤드가 큰 편이다.

#### NUR 페이지 교체

Not Used Recently 페이지 교체기법은 적은 오버헤드로 적절한 성능을 낼 수 있는 기법으로 자주 쓰이는 기법이다.

NUR 기법은 참조 여부와 수정 여부에 따라 페이지를 네 그룹으로 구분한다.
이를 위해 각 페이지당 2개의 하드웨어 비트인 참조 비트(referenced bit)와 수정 비트(modified bit)를 두고 다음과 같이 처리한다.

- 참조 비트
  - 0: 그 페이지가 참조되지 않았을 때
  - 1: 그 페이지가 참조된 적이 있을 때
- 수정 비트
  - 0: 그 페이지 내용이 수정되지 않았을 때
  - 1: 그 페이지 내용이 수정되었을 때

그룹은 다음과 같이 분류한다

- 1 그룹: 참조X, 수정X
- 2 그룹: 참조X, 수정O
- 3 그룹: 참조O, 수정X
- 4 그룹: 참조O, 수정O

NUR 페이지 교체 기법은 다음과 같이 동작한다

- 처음에 모든 페이지의 참조 비트와 수정 비트는 0이다
- 어떤 페이지를 참조하면 그 페이지 참조 비트를 1로 변경한다
- 어떤 페이지 내용이 수정되면 수정 비트를 1로한다
- 참조 비트는 주기적으로 0으로 변경한다
- 페이지 교체가 필요한 경우 그룹 1, 2, 3, 4 순서로 비어있지 않은 그룹에서 교체대상을 선택한다. 이때 그룹 내에서 선택은 무작위이다.

#### 2차 기회 페이지 교체

2차 기회 페이지 교체기법은 FIFO 페이지 교체기법을 보완한 기법으로 참조 비트를 활용한다.

- 처음 모든 페이지 참조 비트는 0이다
- 어떤 페이지에 대한 참조가 이루어지면 그 페이지의 참조 비트를 1로 한다
- 만약 페이지 교체가 필요한 경우 다음 과정을 반복하며 교체 대상을 선택한다
  - FIFO 큐의 선두 항목을 꺼내 참조 비트를 조사
  - 참조 비트가 0이면 그 프레임(미사용)을 교체 대상으로 선택
  - 참조 비트가 1이면 이를 0으로 변경하고 FIFO 큐의 뒤에 넣음

한 페이지에게 주기억장치에 남아 있을 수 있는 second chance를 주는 것이다.
자주 참조되는 페이지는 방복적으로 참조비트를 1로 변경하며 리스트의 앞으로 이동하고, 다시 참조비트를 0으로 변경하여 리스트 맨뒤로 이동한다.

#### 클럭 페이지 교체

2차 기회 알고리즘의 변형으로 클럭 페이지 교체기법(clock page replacement)이 있다.
이 방식은 선형 큐 대신 원형 큐를 사용하여 페이지를 배열한다.

만약 교체가 필요한 경우 현재 포인터가 가리키는 페이지의 참조 비트가 1이면 0으로 하고
포인터만 다음 요소를 가리키도록 움직임으로써 그 페이지를 FIFO 큐의 맨 뒤로 이동시킨 것 처럼 처리한다.

#### 프로세스별 페이지 집합 관리

프로세스마다 유지하는 페이지 집합이 있을 때, 집합의 크기가 적을수록 메모리에 적재할 수 있는 프로세스 수는 많아져 시스템 처리량이 증대될 수 있다.
대신 각 프로세스별로 페이지 부재는 자주 발생할 수 있어 성능이 저하될 수 있다.

반대로 페이지 집합의 크기가 클수록 메모리에 적재될 수 있는 프로세스 수는 줄어들지만 페이지 부재율은 낮아질 것이다.

##### 워킹세트 알고리즘

working set는 가상 메모리 관리기법에서 페이지 부재비율을 감소시키기 위해 Denning이 제안한 모델으로, 하나의 프로세스가 자주 참조하는 페이지 집합을 나타낸다.

워킹세트 알고리즘은 실행 중인 프로그램의 워킹세트를 메모리에 유지시키는 것을 원칙으로 하는 기법이다.
메모리에 새로운 프로세스를 추가할 것인가에 대한 결정은 그 프로세스의 워킹세트가 메모리에 모두 유지될 수 있는지 여부에 따라 결정된다.

하나의 프로세스가 효율적으로 실행되기 위해서는 워킹세트가 메모리내에 유지되어야 하며,
그렇지 않은 경우에는 프로세스가 보조기억장치로부터 계속 페이지를 요구하게 되므로 thrashing이 유발된다.

thrashing이란 페이지 부재가 비정상으로 많이 발생하여 페이지 교체에 너무 많은 시간이 소비되어 시스템 처리량이 급격히 저하되는 현상이다.

워킹세트 알고리즘의 문제점도 존재한다.
과거를 통해 미래를 예층하는 것이 정확하지 않고 워킹세트를 알아내고 이를 계속 업데이트 하는 것도 어려우며, 워킹세트를 구하기 위한 최적값을 알기도 어렵다.

##### PFF 알고리즘

계속해서 부재가 발생하는 프로세스는 페이지 프레임을 너무 적게 가지고 있고,
반대로 절대 부재가 일어나지 않는 프로세스는 실제 너무 많은 페이지 프레임을 가지고 있어서 같은 시스템의 다른 프로세스를 방해할 수도 있다.

따라서 두 극단적인 경우의 중간에서 운영을 하는 것이 이상적이다.
Page Fault Frequency 알고리즘은 프로세스 상주 페이지 세트를 바꾸는 거이다.
상주 페이지 세트란 프로세스가 페이지 부재 때문에 멈추게 되는 빈도에 기초한 페이지 세트이다.

PFF는 페이지 부재 빈도가 상한보다 높으면 들어오려는 페이지는 그 프로세스의 상주 페이지 세트에 추가하고,
페이지 부재 빈도가 하한보다 낮으면 그 사이에 호출되지 않았던 페이지는 모두 제거한다.

PFF의 장점은 프로세스 동작에 따라 유동적으로 상주 페이지 세트를 바꿀수 있다는 점이다.
또한 워킹세트 알고리즘과 비교해서도 매번 세트를 고치는 것이 아니라 페이지 부재가 발생할 때만 세트를 고친다는 장점이 있다.

## 장치관리

### 장치의 개념

입출력 장치는 전용장치, 공용장치, 가상장치로 구분된다.

전용장치는 한 번에 하나의 프로세스에만 할당된다.
이런 구조에 적합한 장치는 테이프 드라이브, 프린터 등이 있다.

공용장치는 여러 프로세스에 할당될 수 있다.
이 때 프로세스의 요구는 스케줄링 기법을 통해 효율적으로 처리되어야 한다.

가상장치는 첫 번째와 두 번째의 조합으로, 디스크 등 공유가능한 장치를 이용하여 전용장치를 공용장치처럼 보이게 하며 여러 프로세스에 할당할 수 있다.

### 장치의 구성

#### 논리적 구성

하드웨어는 장치와 장치제어기(device controller)로 구성된다.

장치 제어기는 장치를 직접적으로 다루는 전자장치로 장치에서 발생하는 각종 데이터를 전자적인 신호로 변환하여 운영체제로 보내고,
운영체제가 요청하는 명령을 받아 장치를 구동하며, 운영체제가 보내는 출력을 장치에 맞게 변환한다.

운영체제에는 장치 드라이버가 있다.
장치 드라이버는 응용 프로그램이 요청한 입출력 요청을 해당 장치에 맞도록 변환해준다.

#### 물리적 구성

장치는 CPU와 메모리, 나머지 장치들이 bus로 연결되어 있어 CPU는 장치제어기에 명령을 보낼 수 있다.

장치제어기에는 몇 개의 레지스터가 있어서 CPU는 레지스터의 값으로 장치 상태를 확인하고 레지스터에 값을 씀으로써 장치에 명령 한다.

CPU가 장치제어기와 통신하는 또 다른 방법으로 메모리 사상 입출력(memory-mapped I/O)이 있다.
메모리 사상 입출력은 메모리의 특정 영역을 장치 제어기의 레지스터와 대응시켜 두고,
CPU는 메모리를 읽고 쓰는 일반적인 명령 수행으로 장치제어기의 레지스터를 읽고 쓰는 것고 동일한 효과를 얻는다.

### 입출력 처리 유형

#### 프로그램 방법

프로그램 방법은 CPU만을 이용하여 입출력을 처리하는 것으로 폴링(polling)을 이용한다.

폴링이란 CPU가 입출력장치의 상태를 지속적으로 확인하여 CPU가 원하는 상태까지 기다리는 것이다.
이렇게 프로그램 방식으로 입출력을 처리하는 것은 CPU 낭비가 심해 비효율 적이다.

#### 인터럽트 방법

인터럽트 방법은 입출력 처리에 인터럽트를 이용하는 것이다.
인터럽트(interrupt)는 어떤 장치가 다른 장치의 작업을 잠시 중단시키고 자신의 상태를 알리는 기능이므로,
장치가 특정 상태가 되었을 때 CPU에게 자신의 상태를 알려준다.

- 입출력 장치가 가용 상태가 되면 인터럽트를 담당하는 인터럽트 제어기에 신호를 보낸다
- 인터럽트 제어기는 CPU에 인터럽트 신호를 보낸다
- CPU는 현재 실행중이던 명령만 마치고 즉시 인터럽트에 응답한다
- 인터럽트 제어기는 이벤트 대상에 대한 정보를 CPU에 보낸다
- CPU는 현재 상태를 보관하고 필요한 입출력 처리를 한 후 원래 프로세스 실행상태로 복귀한다

#### DMA 방법

DMA(Direct Memory Access)는 DMA 제어기를 이용하여 CPU를 통하지 않고 직접 주기억장치에 접근하여 데이터를 전송하는 방식이다.

- CPU는 입출력에 필요한 정보(소스 위치와 크기, 목적지)를 DMA 제어기에 넘긴다, 이때 소스 위치와 목적지 중 하나는 메모리이다
- DMA 제어기는 소스에서 목적지로 데이터를 보내도록 장치제어기에 요청하고, 이 과정을 CPU가 처음 지시한 양이 될 때까지 반복한다
- 원하는 양의 입출력이 끝나면 DMA 제어기는 인터럽트 제어기에 신호를 보내 인터럽트를 발생시켜 CPU에게 입출력 작업이 끝났음을 알린다

DMA 방법은 인터럽트 발생 횟수를 한 번으로 줄여주므로 CPU 효율이 증대된다.

한편 CPU와 DMA 제어기 모두 메모리에 접근하므로 동시에 액세스 한다면 충돌이 발생한다.
이 경우 CPU보다 DMA 제어기에 우선권을 주는데, 이를 cycle stealing이라고 한다.

### 입출력 관리

#### 버퍼링

버퍼(buffer)란 입출력 데이터 등의 정보를 전송할 때 일시적 데이터 저장 장소로 사용되는 메모리의 일부이다.
CPU 데이터 처리 속도와 전송속도의 차이로 인한 문제를 버퍼로 해결한다.

버퍼를 이용하는 가장 단순한 방법인 단일 버퍼링(single-buffering)은
입력장치가 데이터를 버퍼에 저장하면 CPU는 그 데이터를 처리하고 다시 입력장치가 다음 데이터를 저장하고 CPU가 이를 처리하는 방식이다.

하지만 버퍼에 데이터를 저장하는 동안 데이터에 대한 처리가 이루어지지 않으며, 데이터가 처리되는 동안 다른 데이터가 저장될 수 없어 비효율 적이다.

이중 버퍼링(double-buffering)은 데이터의 저장과 처리가 동시에 일어난다.
첫 번째 버퍼에 데이터를 저장하는 동안, 두 번째 버퍼에 데이터가 처리될 수 있다.
반대로 두 번째 버퍼에 데이터를 저장하는 동안 첫 번째 버퍼에 데이터가 처리된다.

이렇게 두개의 버퍼를 교대로 사용하는 것을 플립플롭 버퍼링(flip-flop buffering)이라 한다.

이를 확장하여 여러개의 버퍼를 돌아가며 사용하는 것을 순환 버퍼링(circular buffering)이라 한다.

#### 스풀링

스풀링(Simultaneous Peripheral Operation On Line, SPOOLing)은
입출력 프로세스와 저속 입출력장치 사이의 데이터 전송을 자기 디스크와 같은 고속 장치를 통하도록 하는 일종의 버퍼링이다.

스풀링을 통하면 프로세스 입장에서는 입출력이 빨리 끝난다.
이러한 이유로 스풀링은 독립적으로 사용해아 하는 장치를 여러 프로세스가 동시에 사용할 수 있는 것처럼 보이게하는 가상장치로 변환시켜 준다.

## 저장장치 및 파일

### 저장장치 종류

#### 순차접근 저장장치

순차적으로 기록 및 판독을 하는 저장장치이다. 대표적으로 테이프 장치가 있다.

오늘날 순차 접근 장치의 사용은 점점 줄어들고 있으나, 대량의 데이터 백업용으로 사용되고 있다.

#### 직접접근 젖아장치

직접접근 저장장치는 위치를 지정하여 데이터를 읽거나 쓸 수 있는 장치이다.
임의 접근 저장장치(random access storage devices)라고도 한다.

##### 자기디스크

자기 디스크(magnetic disk)는 자성을 띤 디스크 표면에 데이터를 쓰거나 읽을 수 있는 직접접근 저장장치이다.

자기 디스크는 한 장 이상의 플래터(platter)가 간격을 두고 쌓여 있는 형태이며,
각 플래터마다 기록하고 판독할 수 있는 헤드(head)가 암(arm)에 연결되어 위치한다.
모든 암은 다시 하나의 고정축에 연결되어 있다.

데이터가 저장되는 각 플래터의 표면은 트랙으로 나누어지며, 트랙은 플래터의 중심축을 기준으로 한 동심원의 형태이다.
각 트랙은 다시 섹터로 나누어지는데, 섹터는 일정한 용량을 저장할 수 있는 호(arc)의 형태이다.

플래터가 여러장인 경우 각 플래터의 중심축으로 부터 같은 거리에 있는 트랙들을 모아 하나의 실린더(cylinder)를 구성한다.

자기 디스크에서 데이터를 읽거나 쓰려면 암을 움직여 헤드를 원하는 트랙에 위치시킨 후 플래터를 회전시켜 원하는 섹터를 헤드에 위치시키면 된다.

##### 광 디스크

광 디스크(optical disk)는 자성 대신 빛을 이용하는 것으로, 디스크 표면에 레이저를 쏘아 반사되는 빛이 차이가 생기도록 하는 방법으로 데이터를 쓰거나 읽는다.
광디스크의 종류로는 CD-ROM, DVD, 블루레이 디스크 등이 있다.

광 디스크는 동심원의 트랙들로 구성된 자기 디스크와 다르게 나선형인 하나의 트랙으로 구성되고,
광학 저장장치에 접근하기 위한 주소는 분, 초, 섹터 번호로 이루어진다.

##### SSD

SSD(Solid-State Disk)는 플래시 메모리처럼 읽고 쓰기가 가능하면서 전력 공급이 없어도 데이터가 지워지지 않는 메모리를 이용한 직접접근 저장장치이다.

SSD는 자기 디스크보다 속도가 빠르고 물리적인 장치가 없어 전력소모가 적지만 가격이 비싸고 수명이 짧은 편이다.

### 디스크 스케줄링

디스크 스케줄링(disk scheduling)은 디스크 접근 요구를 효율적으로 처리하는 순서를 결정하는 작업이다.
다중 프로그래밍 컴퓨터 시스템에서는 많은 프로세스가 디스크에 저장된 내용을 읽거나 쓰기 위한 요구를 발생시킬 수 있어 이런 요구를 디스크 큐에 두고 관리한다.

일반적으로 디스크에 접근하는 데 요구되는 시간 요소는

- 탐구시간(seek time): 기계적인 동작에 의해 읽기/쓰기 헤드를 트랙에 위치시킴
- 회전지연시간(rotational latency time) / 탐색시간(search time): 요구된 자료가 읽기/쓰기 헤드 밑에 이를 때까지 디스크를 회전하는데 걸리는 시간
- 전송시간(transfer time): 세 가지 중 가장 빠른 것으로, 자료가 보조기억장치에서 주 기억 장치로 이동하는데 걸리는 시간

대부분의 스케줄링은 탐구시간을 최소화 하는데 집중한다.

스케줄링 정책을 분류하는 기준으로는 처리량(throughput), 평균응답시간(response time), 응답시간의 편차 등이 있을 수 있다.

#### 디스크 FCFS 스케줄링

FCFS(First Come First Serve) 스케줄링은 가장 간단한 형태로, 먼저 도착한 요구가 먼저 처리되는 방법이다.

FCFS는 현재 헤드와 가까운 접근요구가 추가되어도 도착순으로 처리하므로 헤드 이동거리가 길어질 수 있다.

따라서, 디스크의 부하가 커질수록 장치가 포화되고 응답시간이 길어진다.

#### 디스크 SSTF 스케줄링

SSTF(Shortest-Seek-Time-First) 스케줄링에서는 최단 탐구거리(시간)을 가져오는 요구는 큐의 앞에 있지 않아도 우선 처리된다.
SSTF는 실린더 지향의 스케줄링 방법이다.

SSTF 탐색 패턴은 특정 요구를 차별하는 경향이 있다.즈
즉, 중간 범위의 트랙에 비해 최내각과 최외각 트랙이 서비스를 받지 못하는 심각한 국부성을 갖는 경향이 있다.

SSTF는 처리량이 주요 관심사인 일괄처리 시스템에 유용하지만 응답시간의 편차(예상가능성 부족)가 크므로 대화형 시스템에서는 채택되지 않는다.

#### 디스크 SCAN 스케줄링

SSTF의 응답시간 편차를 극복하기 위해 Denning은 SCAN 스케줄링 방법을 개발했다.

SCAN은 선택된 방향에서 가장 짧은 탐색거리를 갖는 요구를 선택한다는 것만 제외하면 SSTF와 동일하게 동작한다.
즉, 선택된 방향이 외부 방향이면 SCAN은 외부방향에서 가장 짧은 거리를 선택하고, 최외각 실린더를 만나면 방향을 바꾸어 작업을 계속한다.

이런점에서 엘리베이터 알고리즘이라고도 불린다.

SCAN 알고리즘에서 헤드가 진행하는 방향의 바로 뒤에 요구가 도착하면 디스크 마지막 트랙까지 갔다가 방향을 바꾸어 돌아올 때 까지 기다려야 하는 문제가 있다.

#### 디스크 N-Step Scan 스케줄링

SCAN 방법의 변형 중 하나로 N-Step SCAN이 있다.

이 방법은 디스크 암(arm)이 특정 방향의 진행이 시작될 때 대기 중이던 요구들만 서비스한다는 것을 제외하면 SCAN 처럼 전후로 움직인다.

진행(sweep)도중 도착한 요구는 한데 모아져서 다음의 반대방향 진행 때 최적 서비스를 위해 정렬된다.
각각의 진행에서 먼저 N개의 요구가 최적의 순서로 서비스된다.

N-Step SCAN은 처리량과 평균 응답시간에 있어 좋은 실행능력을 보이며, SSTF나 SCAN에 비해 응답시간 편차가 작다.
또한 현재 실린더에 많은 수의 요구가 도착할 때 무한 지연이 발생할 가능성을 제거한다.

#### 디스크 C-SCAN 스케줄링

SCAN의 다른 변형으로 C-SCAN(Circular SCAN)이 있다.
C-SCAN 스케줄링은 바깥쪽이든 안쪽이든 한쪽 방향으로 서비스 한다는 것을 제외하면 SCAN과 동일하다.

C-SCAN은 최내각 또는 최외각 실린더에 대한 요구 차별을 제거했으며, 응답 시간의 편차가 매주 작다.
또한 C-SCAN에서 현재 진행 중 도착한 요구는 다음 진행 때 서비스되도록 구현할 수도 있다.

일반적으로 낮은 부하에서는 SCAN 방식이 좋고, 중간 부하 이상에서는 C-SCAN 방식이 좋다.

#### 디스크 LOOK 및 C-LOOK 스케줄링

SCAN류 스케줄링에서는 최외각 트랙으로 이동하거나 최내각 트랙으로 이동할 경우 요구가 없더라도 마지막까지 이동하게 된다.

LOOK 스케줄링과 C-LOOK 스케줄링은 징행 방향에서 앞을 보고 추가적인 서비스 요구가 없을 경우 더 이상 이동하지 않는 알고리즘이다.

#### 디스크 SLTP 스케줄링

높은 부하상태에서는 특정 실린더에 대한 다수 참조가능성이 증가한다.
따라서 탐구시간 최적화뿐만 아니라 회전지연시간 최적화도 고려하는 것이 유용하게 되었다.

탐구시간 최적화의 SSTF 방식과 유사한 것이 회전지연시간 최적화를 위한 SLTF(Shortest Latency Time First)이다.

일단 디스크 암이 특정 실린더에 도착하면 그 실린더의 여러 섹터에 대해 여러 요구가 있을 수 있다.
SLTF 방법은 이런 모든 요구들을 검사한 후 가장 짧은 회전 지연시간을 갖는 요구를 우선 서비스한다.

이 방식은 이론적인 최적값과 거의 일치한다는 것이 밝혀졌다.
회전 시간 최적화는 때로는 섹터 큐잉(sector queueing)이라고 불린다.

디스크 주소는 트랙과 섹터로 이루어지므로 헤드가 고정되어 탐구시간이 필요없어지게 된다.

### 파일 관리

#### 파일관리자의 요소

파일 관리자(file manager)는 운영체제의 주요 구성요소로서 파일에 의해 사용되는 자원을 관리할 뿐만 아니라
파일을 생성, 삭제, 수정하거나 파일에 접근하는 것을 제어하는 소프트웨어로 다음과 같은 네 가지 요소가 포함된다.

- 파일에 저장되어 있는 데이터에 접근하는 방식에 관련되는 액세스 방식
- 파일을 저장, 참조, 공유할 수 있도록 하며 안전하게 보호될 수 있도록 하는 기법을 제공하는 파일 관리
- 보조기억장치에 파일을 저장하는 데 필요한 공간을 할당하는 일과 관계되는 보조기억장치 관리
- 파일의 정보가 소실되지 않도록 보장하는 일에 관계되는 파일의 무결성 유지

이러한 파일 관리 시스템은 보자기억장치 중 특히 디스크 장치를 관리하는 일과 연관 된다.

#### 파일관리자의 기능

- 사용자가 파일을 생성, 수정 및 삭제할 수 있게 하는 기능
- 타인의 파일을 공동으로 사용할 수 있게 하는 기능
- 파일 시스템의 파일 공유기법은 read access, write access, execute access 또는 이들을 여러 형태로 조합한 것을 제공
- 사용자가 각 응용에 적합한 구조로 파일을 구성할 수 있게 하는 기능
- 불의의 사고로 인해 정보 손실이나 고의적 정보 파괴를 방지하기 위한 백업 및 복구 기능
- 물리적인 장치 이름 대신 기호화된 이름(symbolic name)을 사용하여 파일을 참조할 수 있게 하는 기능
- 정보가 안전하게 보호되고 비밀이 보장되게 하는 기능
- 사용자 편의 인터페이스 제공

#### 파일 구조와 접근 방식

##### 순차 파일

순차 파일(sequential file)은 레코드가 물리적 순서에 따라 저장되어 있는 파일이다.

"다음" 레코드는 실제로 현재 레코드 바로 뒤에 저장되어 있는 레코드를 의미하며 이러한 구조는 물리적으로 순차적 성질을 가진 자기테이프에 이용된다.

##### 인덱스된 순차 파일

인덱스된 순차 파일(indexed sequential file)은 레코드가 각 레코드의 키를 기준으로한 논리적 순서대로 배열되어 잇는 파일이다.

시스템은 일부 주요 레코드의 실제 주소가 저장된 인덱스를 관리하고 인덱스에 의해 직접 액세스 될 수 있다.

##### 직접 파일

직접 파일(direct file)은 레코드가 직접 액세스 기억장치(direct access storage device)의 물리적 주소를 통해 직접 액세스 되는 파일이다.

#### 디스크 공간 할당

##### 연속 할당 기법

파일을 보조기억장치의 연속된 공간에 할당하는 것을 연속 할당(contiguous allocation) 기법이라 한다.

연속 할당 기법의 장점은 논리적으로 연속된 레코드들이 물리적으로 서로 인접하게 보조기억장치에 저장되므로,
논리적으로 연속된 레코드들이 전체 디스크에 펴져있는 경우보다 액세스 시간이 감소한다.

또한 디렉토리에는 각 파일의 시작주소와 파일의 길이만을 유지하면 되므로 파일의 디렉토리를 구현하기 쉽다.

그러나, 파일이 디스크에서 제거되면 그 파일이 차지하고 있던 공간에서 외부 단편화와 같은 문제가 발생한다.
즉, 인접한 공간을 합병해야 하는 문제가 발생하며, 새로운 파일을 넣을 공간을 만들기 위해 주기적 집약(compaction)이 필요하다.

파일의 크기가 시간에 따라 변하는 경우 역시 연속 할당이 어렵다.

##### 불연속 할당 기법

불연속 할당 기법은 섹터 또는 정해진 수의 섹터로 구성된 블록 단위로 공간을 할당한다.

시스템은 현재 파일이 저장되어 있는 블록으로부터 가장 가까운 거리에 있는 블록을 선택하여 그 파일에 추가 할당하고 포인터로 연결한다.
블록할당 기법에는 블록 체인 기법, 인덱스 블록 체인 기법, 블록 지향 파일 사상기법 등의 ㅂ아법이 있다.

불연속 할당 기법의 장점은 단편화나 파일 확장 등의 연속 할당 기법의 문제를 해결한다는 것이다.
반면 파일 공간이 분산되어 논리적으로 연속되 레코드를 검색하는 경우 성능저하가 발생하고, 포인터 관리를 위한 연산 및 공간이 필요하다.

## 분산 운영체제
