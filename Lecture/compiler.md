# 컴파일러

## 컴파일러 개요

- 원시 프로그램 -> 번역기 -> 목적 프로그램
- 어셈블리어 프로그램 -> 어셈블러 -> 기계어 프로그램
- 고급언어 프로그램 -> 컴파일러 -> 어셈블리어/기계어 프로그램
- 고급언어 프로그램 -> 프리프로세서 -> 고급언어 프로그램
- 고급언어 프로그램 -> 인터프리터 -> 실행결과

컴파일러는 목적코드에 따라 다음으로 분류할 수 있다

- native compiler
  - 일반적으로 사용되는 컴파일러
  - 컴파일러가 목적코드를 생산하고 나면 목적코드는 바로 컴퓨터에서 실행된다

- cross compiler
  - 임베디드 프로그램처럼 목적코드가 다른 컴퓨터나 운영체제에서 실행되도록 번역

- bytecode compiler
  - Java 언어가 대표적이다
  - 원시프로그램을 자바 바이트 코드 형태로 번역한다
  - 바이트코드는 자바 가상 머신에서 실행될 수 있는 코드이다

### 인터프리터

인터프리터의 처리과정을 보면, 고급언어로 작성된 원시 프로그램을 중간코드로 변환하고,
변환된 중간코드를 명령어 단위로 가져다가 디코드하고 실행을 한다.

그리고 명령어의 주소를 하나 늘린 후, 다음 명령어를 가져온다.

- 시작
- 다음 명령어 호출(fetch)
- 명령어 디코드(decode)
- 지정된 피연산자 호출
  - 원시연산 실행
    - 명령어 주소 하나 증가 `(다음)`
  - 실행중지 연산 `(종료)`
  - 지정된 연산으로 분기
    - 원시연산 실행
    - 명령어 주소 하나 증가 `(다음)`

### 컴파일러의 논리적 구조

- 원시 프로그램
- 어휘분석
- 구문분석
- 의미분석
- 중간코드 생성
- 코드최적화
- 목적코드생성
- 목적프로그램

#### 어휘분석 (lexical analysis)

어휘분석 단계에서는 원시 프로그램을 읽어 문장을 구성하고 있는 최소 단위인 어휘들을 떼어,
이 어휘들이 올바른지 분석하는 일을 한다.

따라서 모든 어휘를 정의한 문법(grammar)이 필요하다.
어휘분석 단계에서 문법에 의해 어휘가 분석되는데 올바르지 않으면 오류메시지가 출력되고,
올바른 경우 token 형태로 출력된다.

어휘 토큰은 의미 있는 최소의 문법적 단위(syntactic entity)가 되고,
이와 같은 일을 하는 것을 어휘분석기(lexical analyzer) 혹은 스캐너(scanner)라 한다.

토큰은 예약어(reserved word)나 상수(constant), 연산자(operator), 식별자(identifier),
괄호/따옴표/세미콜론등의 구분자(delimiter)등이 있다.

#### 구문분석 (syntax analysis)

구문분석 혹은 파싱(parsing)이라고 하며,
구문분석기(syntax analyzer) 혹은 파서(parser)가
어휘분석 결과인 토큰을 입력받아 이어지는 토큰들이 올바른 문장구조를 갖고 있는지 검사한다.

구문분석 단계에서도 문장구조를 정의할 문법이 필요하다.

문장을 정의한 문법에 맞는지 분석하는데,
올바른 문장에 대해서는 문장에 대한 구문구조(syntatic structure)를 만들어 출력하고
올바르지 않은 문장에 대해서는 오류메시지를 출력한다.

구문구조는 토큰들을 단말노드(terminal node)로 하는 tree 형태로 표현되는데,
이 트리를 parse tree라 한다.

parse tree는 중간코드 생성단계에서 이용된다.
parse tree에서 불필요한 정보인 식별자, 숫자, 식 등을 제거하고
다음 단계에서 필요한 정보만으로 구성된 트리를 구문트리(syntax tree)라고 한다.

#### 의미분석 (semantic analysis)

구문트리에 어떤 의미가 있고 어떤 기능을 수행하는지 분석하고,
수행환경을 조성하는 것을 의미분석기 (semantic analyzer)라 한다.

구문트리를 보며 산술식과 각 문장의 연산자 및 피연산자를 인식하고 type checking 등을 한다.

#### 중간코드 생성 (intermediate code generation)

중간코드 생성은 구문분석 단계에서 만들어진 구문트리를 이용하여 코드를 생성하거나,
구문지시적변환(syntax-directed translation)으로 이루어진다.

구문지시적 변환은 문법규칙이 reduce될 때 그 규칙에 맞는 코드생성 루틴을 부름으로써
중간코드 생성기(intermediate code generator)에 의해 중간코드를 생성한다.

`ABC := E * 3.14 + ABC / E`는 구문분석에서 얻어진 parse tree에 의해 다음과 같은 quadruple 중간코드를 얻는다

| 중간코드 | 의미 |
| --- | --- |
| `(*, E, 3.14, T0)` | `T0 = E * 3.14` |
| `(/, ABC, E, T1)` | `T1 = ABC / E` |
| `(+, T0, T1, T2)` | `T2 = T0 + T1` |
| `(:=, T2, Φ, ABC)` | `ABC := T2` |

#### 코드최적화 (code optimization)

코드를 효율적으로 만들어 코드 실행시 기억공간이나 실행시간을 절약하기 위한 단계이다.

최적화는 방법에 따라 여러가지로 나눌 수 있다

- Local(Peephole) optimization / Global optimization
- 단일문 최적화 / Loop 문장에서 최적화
- 실행속도 최적화 / 기억장소 최적화

지역최적화란 부분적인 관점에서 비효율적인 코드를 구분해내고, 이를 효율적으로 수정한다

- 중복된 LOAD, STORE 명령문 제거
- 불필요한 코드 제거
- 제어흐름 최적화
- 식(expression)의 대수학적 간소화(algebraic simplication)
- 연산의 세기경감(strenth reduction)
- 상수전파(constant propagation)
- 복사전파(copy propagation)
- 공통부분식(common subexpression) 제거
- 결합 변형
- ...

전역최적화는 전체적인 관점에서 보다 효율적인 코드로 수정한다

- 코드 이동(code motion)
- 귀납변수(induction variable) 최적화
- 루프융합(loop fusion)
- 루프전개(loop unrolling)
- ...

#### 목적코드 생성(code generation)

컴파일 과정의 마지막 단계로 연산을 수행할 레지스터를 선택하거나 자료에 기억장소의 위치를 정해주며,
실제로 목적기계어에 대한 코드를 생성하는 단계이다.

중간 코드 생성 단계에서 만들어진 중간코드들을 기계명령어(machine instruction)으로 바꾸어준다

### 컴파일러의 물리적 구조

컴파일러의 논리적 구조를 실제로 구현하는 경우 물리적 구조는 논리적 구조와 반드시 일치하지는 않는다.

컴파일러 구현에서는 여러단계를 모아서 하나의 모듈로 묶을 수 있는데, 이를 pass라 한다.
컴파일러의 구현방법으로는 크게 두 가지가 있다.

- one-pass compiler: 컴파일러의 전 과정을 하나의 패스로 구현
  - 초창기의 컴파일러
  - forward jump 처리를 위해 빈칸으로 남긴 부분을 backpatching으로 채움
  - 효율성이 좋고 실행속도가 빠르다

- two-pass compiler: 컴파일러의 구성을 중간코드를 기점으로 하여, 전/후반부로 구분함
  - 전반부: 어휘분석, 구문분석, 중간코드 생성
  - 후반부: 코드최적화, 목적코드 생성
  - 기계코드 표현에 제약을 받고 실행속도가 느리다
  - 이식성이 좋고 중간코드를 이용하여 최적화 하므로 기계와 독립적인 최적화 가능
  - 하나의 패스가 사용했던 공간을 재사용하므로 기억장소 절약 가능

### 간단한 컴파일러

`ABC := E * 3.14 + ABC / E`

문제를 간단히 하기 위해 조건을 한정하자

- 연산결과를 저장하는 누산기는 1개
- 연산자인 곱셈, 나눗셈이 덧셈, 뺄셈보다 연산순위가 높다
- 연산자인 덧셈, 뺄셈은 치환연산자 (:=)보다 연산순위가 높다

순서는 다음과 같다

- 컴파일러는 입력장치를 통해 원시 프로그램 string을 기억장치로 읽어 들인다
- 기억장치 내에 있는 문자의 열을 한 문자씩 왼쪽부터 scanning 한다
- 공백은 건너뛰고, 처음 토큰부터 어휘분석기로 종류를 판별한다
- 식별자를 판별하면 기호표에 기록한다 (변수, 상수 ...)
- 토큰에대한 식별번호를 기록한다
- 피연산자 || 연산자 스택에 기록한다
- 연산자 스택에 이미 자료가 있다면 연산자 우선순위를 비교한다

스택의 TOP 연산자가 우선순위가 높다면(연산처리)

- 연산자 스택의 TOP 요소와 피연산자 스택 요소 2개를 꺼내 연산한다
- 누산기의 계수기를 통해 다른 연산결과가 저장되어 있는지 확인한다
  - 다른 결과가 있다면 누산기를 사용하기 위해서 내용을 임시저장소에 저장해야 한다
  - 누산기 계수기를 따라가 임시기억장소인 작업용 번지의 주소로 교체한다
- 누산기의 식별번호를 피연산자 스택에 넣는다
- 누산기의 계수기에 피연산자 스택의 번지를 저장한다
- 누산자 계수기를 증가시킨다

현재 연산자가 우선순위가 높다면: 연산자 스택에 기록한다

위와 같은 과정을 반복한고, 문장이 끝났다는 구분자 `;`를 만나면 스택을 정리하기 시작한다

스택정리는 연산처리 부분을 반복하며 이루어진다

## 형식언어와 오토마타

### 형식언어의 기초

- 알파벳 < 문자열 < 형식언어

- 형식언어(formal language): 어떤 알파벳에서 얻은 symbol들로 구성되는 문자열들의 집합
- 알파벳: 기호들의 유한집합
- 문자열: 알파벳을 구성하는 기호가 0 또는 1개 이상 나열(sequence)된 것

- 문자열의 길이: 문자열을 이루는 기호들의 개수를 문자열 길이(cardinality)라 하고 `|w|`로 표시한다
- 공문자열: 문자열의 길이가 0인 것을 공문자열(empty string)이라고 한다

- `T*` (star closure): 공문자열을 포함하여, T에 속하는 기호들로 이루어질 수 있는 모든 문자열의 집합
- `T+` (positive closure): `T*`에서 공문자열을 제외한 모든 문자열의 집합을 나타낸다

앞의 정의들로 언어(language)를 정의하면

> 알파벳 T에 대한 언어 L은 `T*`의 부분집합이다

### 형식문법

형식문법이란 형식언어를 생성하기 위한 규칙들로 다음과 같이 정의할 수 있다

- 형식문법 `G = (Vn, Vt, P, S)`
  - `Vn`: 논터미널 기호들의 유한집합
  - `Vt`: 터미널 기호들의 유한집합
  - `P`: 생성규칙의 집합: `a -> b`, `a ∈ V+`, `b ∈ V*`
  - `S`: `Vn`에 속하는 기호로 다른 논터미널과 구별하여 시작기호라고 한다

기호들의 일반적인 표기법을 나타내면 다음과 같다.

- A, B, C 와 같은 영문자 대문자로 구성된 기호와 시작기호를 나타내는 S는 논터미널 기호이다
- `<`와 `>`로 묶어서 나타낸 기호도 논터미널 기호이다
- a, b, c와 같은 영문자 소문자로 구성된 기호와 +, -와 같은 연산자기호, 괄호나 쉼표와 같은 구분자, 0, 1, 2와 같은 아라비아 숫자들은 터미널 기호이다
- X, Y, Z와 같은 영문자 끝부분의 대문자는 터미널 기호와 논터미널 기호를 나타내는 문법기호이다
- 영문자 끝부분의 소문자인 u, v, w, x, y, z 등은 터미널 기호들로 이루어진 문자열을 나타낸다
- α, β, γ와 같은 그리스어 소문자는 문법기호로 구성된 문자열을 나타낸다
- 아무런 언급이 없으면 첫 번재 생성규칙의 왼쪽에 있는 기호가 시작기호이다

#### chomsky 계층구조

type0 > type1 > type2 > type3

- type 0: α → β: 위축형 문법 포함: 튜링기계

- type 1: α → β, |α| ≤ |β|: 비위축형 문법: linear-bounded 오토마타

- type 2 (Context Free Grammar) <- BNF: A → γ, A ∈ Vn: 푸시다운 오토마타

- type 3 (Regular Grammar): `non-terminal → [non-terminal]terminal`: 유한 오토마타
  - 우선형(우측-B 증가): A → tB, A → t
  - 좌선형(좌측-B 증가): A → Bt, A → t

### 정규표현

- Φ: 공집합
- ε
- a ∈ Vt: {a}
- 만일 P, Q가 정규언어 Lp, Lq를 표현하는 정규표현이라 하면
  - (P+Q): `a+b`
  - (P·Q): `ab`
  - (P*): `a*`, `(ab)*`, `(a+b)*`

### 정규언어와 유한 오토마타 (Finite Automata)

#### 유한 오토마타

> 문자열(w) -> 유한 오토마타 (`w ∈ L(T)`) -> Yes | No

문자열 w를 입력받아서 w가 언어 L(T)의 문장이면 Yes를 답하고 그렇지 않으면 No를 답하는 프로그램이다

일반적으로 컴파일러 중에서 어휘분석기는 대표적인 유한 오토마타이다.

유한 오토마타를 표현하는 방법에는 다음 두 가지가 있다.

- 정의에 따라서 5가지의 구성원소를 형식에 맞게 정확히 표현하는 방법
  - Q: 상태들의 유한집합
  - Σ: 입력기호들의 유한집합
  - q0: 시작상태 또는 출발상태 (q0 ∈ Q)
  - F: 종료상태들의 집합 (F ∈ Q)
  - δ: 상태전이함수 (Q X Σ -> 2^Q(Q의 멱집합))

- 상태전이도(transition diagram)라는 그림을 이용하여 비형식적으로 표현하는 방법
  - 오토마타의 각 상태를 노드로 나타내는 그림
  - 상태전이도에서는 상태 q에서 p로 가는 지시선 위에 a를 표기한다
  - 종결상태는 이중 원으로 나타내고, 시작상태는 시작 지시선으로 표시하는 directed graph이다

#### DFA(결정적 유한 오토마타) / NFA(비결정적 유한 오토마타)

- DFA: 하나의 입력문자열에 대하여 오직 하나의 다음 상태가 결정되는 것
- NFA: 어떤 상태에서 주어진 하나의 입력기호를 보고, 갈 수 있는 다음 상태가 하나 이상 존재할 수 있는 유한 오토마타이다

#### DFA와 NFA의 동치관계

NFA는 언어의 구조를 쉽게 표현할 수 있는 반면, DFA보다 프로그램으로 구현하기 어렵다.
따라서 일반적인 구현은 DFA로 하게되고 NFA에서 변환하게 된다.

- ε-전이가 있는 NFA를 DFA로 변환
  - ε-closure(S): S가 한 개일 경우 S와 S로 부터 레이블이 ε인 지시선으로 도달할 수 있는 모든 상태의 집합
  - T가 하나 이상의 상태집합으로 되어 있는 경우에 ε-closure(T)는 T속에 있는 각 상태에 대해 위와 같은 방법으로 집합군은 구하여 합한것
  - 변환
    - ε-NFA의 시작상태 q0에 대해 ε-closure(q0)를 구하고 ε-closure(q0)를 DFA의 시작상태로 놓는다
    - ε-closure(q0)의 원소들에 대해서 ε-NFA에 있는 ε을 제외한 각각의 입력기호에 대해 갈 수 있는 상태집합을 T1, T2 ...
    - ε-closure(T1), ε-closure(T2) ... 를 구하여 DFA의 새로운 상태로 만들고, 이전에 만들어진 상태면 지시선만 만든다
    - 과정을 되풀이하여 새로운 상태가 나타나지 않을 때 까지 계속한다
    - 만들어진 상태중에서 ε-NFA의 종료상태를 포함하는 상태는 모두 DFA의 종료상태가 된다

- ε-전이가 없는 NFA를 DFA로 변환
  - NFA에 의해서 인식되는 언어를 L이라 하면, L을 인식하는 DFA가 존재한다
  - L을 인식하는 NFA M = (Q, Σ, δ, q0, F)라 놓으면
  - DFA M' = (Q', Σ', δ', q0', F')는 다음과 같이 구성된다
    - Q' = 2^Q
    - F = {M의 종료상태를 포함하는 Q'안에 있는 모든 상태의 집합}
    - q0' = [q0]

#### DFA의 상태수 최소화

상태수를 최소화하는 방법은 동치관계를 이용하여 상태수를 합침(state merge)으로써 상태수를 최소화할 수 있다.

- w ∈ Σ* 에 대해서 q1에서 w를 다 본 상태가 q3이고 q2에서 w를 다 본 상태가 q4일 때, q3, q4 중 하나만 종료상태에 속하면 q1은 q2로부터 구별(distinguish)된다고 말한다
- 만약 상태집합 Q속에 상태가 도달 가능하지 않고, Q의 서로 다른 두 상태가 구별 가능하지 않다면 축약(reduce)될 수 있다

상태수 최소화는 다음과 같은 과정으로 이루어진다

1. 시작상태로부터 도달 불가능한 상태를 모두 제거한다
2. 초기의 동치관계인 [종료상태]와 [미결상태]의 두 동치류로 분할한다
3. 같은 입력기호에 대해 서로 다른 동치류로 가는 지시선이 존재하면 또 다른 분할을 하여 새로운 동치류를 만든다
4. 3의 과정을 되풀이하여 더 이상 새로운 분할이 일어나지 않을 때까지 반복한다
5. M의 종료상태에 속하는 상태가 동치류 속에 들어 있으면 이 동치류는 M'의 종료상태이다

#### 정규문법, 정규표현, 유한 오토마타의 동치관계

정규문법, 정규표현, 유한 오토마타는 서로 변환되는 동치관계이다

정규표현을 유한 오토마타로 변환하는 과정은 다음과 같다

- 정규표현으로부터 NFA를 구한다
- NFA를 DFA로 변환한 다음 최호화된 DFA를 구한다

유한 오토마타를 정규문법으로 변환하는 과정은 다음과 같다

- 상태전이도에서 각각의 상태를 하나의 논터미널이라 하고 입력기호를 터미널 기호라 하자
- 정규문법을 작성하는데 왼편에는 상태를 나타내는 논터미널을 쓴다
- 오른편에는 전이지시선 위에 있는 입력기호인 터미널 기호를 쓰고 다음에 전이되는 상태를 쓴다

## 어휘분석

### 어휘분석(lexical analysis)이란

어휘분석은 원시 프로그램을 구성하는 문자들을 하나의 긴 문장열로 보고 문자를 차례대로 scanning하고 token이라는 단위로 변환하는 것이다.

어휘분석을 담당하는 도구를 어휘분석기/scanner 라고 한다.

토큰이란 의미 있는 문법적 단위인데, 일반적인 프로그래밍 언어에서는 5종류의 토큰을 사용한다

- 식별자(identifier): SUM, A, B와 같이 프로그래머가 정의하는 변수
- 상수(constant): 1, 2, 3, 'abc'와 같이 정수형 상수, 실수형 상수, 문자형 상수
- 예약어(reserved word): IF, WHILE과 같이 언어 구현시 이미 정의되어 있는 지정어
- 연산자(operator): -, +, *, / 등고 같이 연산시 사용되는 기호
- 구분자(delimiter): (, [, ; 등과 같이 단어와 단어를 구분하기 위해 사용되는 기호

일반적으로 토큰은 토큰번호와 토큰값의 순서쌍으로 표현된다.
토큰번호란 각각의 토큰을 구분하기 위해서 고유의 내부번호를 부여한 정수코드이고, 토큰값은 기호에서 토큰의 위치로 표현된다.

어휘분석기는 토큰번호와 토큰값을 출력하기 위해서 입력에 대해 복귀 값(return value)을 갖고 있어야 하며,
주어진 모든 문법에 대한 토큰번호와 토큰값을 가지고 있어야 한다.

그러나 프로그래머가 사용한 식별자와 상수에 대한 토큰값과 속성을 나타내는 정보는 기호표(symbol table)에 별도로 보관된다.

어휘분석 단계에서 어휘분석기는 원시 프로그램을 분석하여 토큰열을 생산하면서 얻어진 식별자에 대해 기호표를 검색하여,
기호표에 이미 있으면 다시 작성하지 않고 없으면 기호표에 식별자를 삽입한 뒤
구문분석기에게 식별자에 대한 토큰번호와 값으로 기호표 인덱스를 전달한다.

### 어휘 분석기의 설계

어휘분석기를 설계하려면 우선 문법이 주어져야 한다. 문법의 형태는 앞에서 살펴본 정규문법의 형태이다.
그리고 주어진 문법의 문법단위에 대한 token table을 작성한다. token table은 어휘분석기에서 돌려 주는 값을 나타낸다.

문법을 보고 NFA를 구성하고, NFA를 DFA로 변환한다음 DFA를 최소화시키면 어휘분석기가 된다.
여기에 최소화된 DFA에 의해 검색하면서 기호표를 작성할 수 있도록 해야 한다.

### 어휘분석기 구현 고려사항

분류한 토큰들은 항상 사용되는 것이 아니라 문법이 어떻게 주어지느냐에 따라 다르다.
그러므로 어휘분석기를 구현할 때는 문법이 어떻게 주어지는지 명확하게 정의되어야 하며,
명확하게 정의된 문법에 의해서 토큰의 종류를 나열해야 한다.

또한 상태전이도의 순서를 어떻게 주느냐에 따라 어휘분석을 하는 시간이 달라진다.
그러므로 프로그램 작성시 어느 토큰을 많이 사용하는지를 파악하여 어휘분석기를 구현해야 한다.

## Context-Free 언어와 문법의 효율화

### Context-Free 언어와 푸시다운 오토마타

context-free 문법은 산술식이나 블록 구조를 표헌하는데 효율적이기 때문에 프로그래밍 언어 중에서 가장 널리 사용되고 있다.
context-free 문법은 자연언어(natural language)를 표현하기 위해 도입되었다.

context-free언어는 정규언어보다 표현범위가 넓어서, 이것을 인식하는 push-down 오토마타를 구현하는 일은 유한 오토마타를 구현하는 일보다 어렵다.

### 유도트리

- 좌단유도(leftmost derivation): 유도과정의 각 단계에서 문장형태(sentential form)의 가장 왼쪽에 있는 논터미널 기호를 계속 대체하는 경우
- 우단유도(rightmost derivation): 좌단유도와 반대로 가장 오른쪽에 있는 논터미널 기호를 계속 대체
- 좌파스(left parse): 하나의 문장을 만들때 좌단유도에 의해서 적용된 일련의 생성규칙 순서
- 우파스(right parse): 우단유도에 의해서 적용된 생성규칙의 순서의 역순

좌파스와 우파스는 구문분석의 방법과 깊은 연관관계가 있다.
top-down 구문분석은 좌파스를 생성하고, bottom-up 구문분석은 우파스를 생성한다.

또한 구문분석을 하는 과정은 문장이 유도되는 과정을 트리 형태로 표현하는데, 이를 유도트리(derivation tree)혹은 파스트리(parse tree)라 한다.

CFG(context-free grammar)에 대한 유도트리는 다음과 같이 정의한다

- 모든 노트(vertex, node)는 문법기호를 레이블(lable)로 갖는다
- 루트(root)의 레이블은 시작기호 S이다
- 만약 어떤 노드가 하나 이상의 자식노드(child node)를 갖는다면 이 노드는 논터미널 기호를 레이블로 갖는다
- 왼쪽부터 순서적으로 X1, X2, ... Xn의 n개의 자식노드를 갖는 어떤 노드 A가 존재한다면 생성규칙이 존재한다
- 만약 어떤 노드가 자식노드를 하나도 가지고 있지 않다면, 이 노드를 leaf(terminal node)라 한다

### 모호성

구문분석 단계에서는 출력으로 유도트리를 생성하는데 문법이 모호한 경우에는 문장의 유도트리를 결정적으로 구성하기 어렵다.
따라서 구문분석기 구현이 복잡해지고 구문분석을하는 시간이 오래걸리는데, 이를 막기위하여 모호하지 않은 문법으로 바꿔줘야 한다.

- 모호한 문법에 연산자 우선순위와 결합법칙을 적용하여 모호하지 않은 문법으로 바꿀 수 있다.
- 하나의 context-free 언어를 생성하는 모든 문법이 모호하다면, 이 언어를 inherently ambiguous라고 한다.
- 모호성 문법 외에도 구문분석을 하는데 효율을 높이기 위해 적당한 문법으로 바꾸어줄수 있는데, 이를 context-free 문법의 단순화라고 한다.

### 불필요한 생성규칙의 제거

불필요한 기호는 터미널 문자열을 생성할 수 없는 논터미널 기호이거나 시작기호로부터 도달 불가능한 기호를 말한다.
이와같이 불필요한 기호를 가지고 있는 생성규칙을 불필요한 생성규칙이라고 한다.

### ε-생성규칙의 제거

ε-생성규칙이란 A -> ε 형태의 생성규칙을 갖는 것을 말한다.
만약 ε이 L(G)안에 없다면 ε-생성규칙을 완전히 제거할 수 있다.

### 단일 생성규칙의 제거

단일 생성규칙(unit production)이란 생성규칙 중 생성규칙의 오른쪽이 단 한개의 논터미널로 구성되어 있는 생성규칙이 존재하는 경우를 말한다.

### left-factoring

같은 기호들을 prefix로 갖는 두 개 이상의 생성규칙이 존재할 경우, 공통된 prefix를 인수분해하는 것을 left-factoring이라고 한다.

### left-recursion의 제거

문법이 어떤 문자열 α에 대해 A -> Aα의 유도과정이 존재하는 경우를 left-recursive하다고 말하며,
이러한 문법은 top-down 구문분석 시에 같은 생성규칙이 반복적으로 적용되어 무한루프에 빠지게 되므로 구문분석을 어렵게한다.

left-recursion에는 두 가지가 있다.

- immme-diate left-recursion: A -> Aα 형태의 생성규칙
- indirect left-recursion: A -> Aα 유도과정이 존재하는 경우

### 푸시다운 오토마타

푸시다운 오토마타의 대표적인 예로서는 구문분석기가 있다.
푸시다운 오토마타는 유한 상태제어와 입력 테이프 외에 무한정의 용량을 가진 스택으로 구성된다.

푸시다운 오토마타에는 비결정적 푸시다운 오토마타와(NPDA)와 결정적 푸시다운 오토마타(DPDA)의 두 종류가 있다.

## 구문분석

구문구조가 주어진 규칙에 맞는지를 검사하는 것을 구문분석(syntax analysis)혹은 파싱(parsing)이라고 한다.

이러한 구문분석을 담당하는 도구를 구문분석기(syntax analyzer, parser)라고 한다.
일반적으로 구문분석의 출력으로 생성되는 트리는 유도트리(derivation tree)와 같은 모양을 갖는데,
유도과정을 나타낼 때는 유도트리라 하고, 구문분석기에 의해 생성될 때는 파스트리라고 한다.

구문분석은 파스트리를 어떤 순서로 만들어 가느냐에 따라 top-down 방법과 bottom-up 방법의 두 종류로 나눌 수 있다.

### Bottom-up 구문분석

bottom-up 구문분석 방법은 주어진 문자열로부터 reduce에 의해 시작기호를 찾아가는 방법이다.

> 문장 -> 시작기호

(예) Top-down id + id * id 좌단유도 (id: identifier)

- E -> E + E
- -> id + E
- -> id + E * E
- -> id + id * E
- -> id + id * id

(예) Bottom-up id + id * id 우단유도 (id: identifier)

- id + id * id (`id`)
- -> E + id * id (`id`)
- -> E + E * id (`id`)
- -> E + E * E (`E * E`)
- -> E + E (`E + E`)
- -> E (**handle**)

#### shift-reduce 구문분석

| 단계 | 스택 | 입력 | 구문분석 행동 |
| --- | --- | --: | --- |
| 0 | $ | id+id*id $ | `shift id` |
| 1 | $id | +id*id $ | `reduce E -> id` |
| 2 | $E | +id*id $ | `shift +` |
| 3 | $E+ | id*id $ | `shift id` |
| 4 | $E+id | *id $ | `reduce E -> id` |
| 5 | $E+E | *id $ | `shift *` |
| 6 | $E+E* | id $ | `shift id` |
| 7 | $E+E*id | $ | `reduce E -> id` |
| 8 | $E+E*E | $ | `reduce E -> E*E` |
| 9 | $E+E | $ | `reduce E -> E+E` |
| 10 | $E | $ | `accept` |

스택 최상단 / 입력 좌측 순위 비교로 연산결정: 터미널-터미널 / 기호-기호

### 여러가지 순위문법과 용어

- FIRST(A): 문자열 A로부터 유도되어, 첫 번째로 나타날 수 있는 터미널 기호들의 집합
  - `FIRST(E) = (FIRST(T) ring sum FIRST(E')`)
  - `A ring sum B = A if ε not ∈ A`
  - `A ring sum B = (A-ε) ∪ B if ε ∈ A`

- FOLLOW(A): A 뒤에 나오는 터미널 기호들
  - if A == 출발기호, $ ∈ FOLLOW(A)
  - if B -> αAβ, β != ε, FOLLOW(A) ⊃ FIRST(β) (ε 제외)
  - if B -> αAβ & B => ε, FOLLOW(A) ⊃ FOLLOW(B)

### 단순순위 구문분석

단순순위 문법을 가지고 구문분석을 하는 방법으로 논터미널과 터미널, 논터미널과 논터미널 사이에 순위관계를 부여해서 구문분석을 한다.
순위관계를 트리로 표현했을 때, 자식노드가 부모노드보다 순위가 높다.

그러나 단순순위 구문분석에서는 핸들 결정 문제점때문에 부정확하다.

### LR 구문분석

- 모호하지 않은 CFG이면 모두 가능
- Backtracking이 없다

#### SLR(Simple LR) 구문분석

#### CLR(Canonical LR) 구문분석

#### LALR(LookAhead LR) 구문분석

### Top-Down 구문분석

## 의미분석과 기호표

### 의미분석 개요

- 상수정의 과정
  - 상수 이름 기호표에 등록
  - 이후 기억장소 배정 및 초기값 설정

- 유형(type)정의 과정
  - 유형의 자료구조 구성 및 보관
  - 유형설명자(유형의 자료구조 크기, 성격 ...) 작성
  - 기억장소 배정 때 정보 제공

- 변수의 유형선언
  - 변수의 유형에 따른 유형 설명자와 변수명칭이 기호표에 함께 등록
  - 각 변수는 기억장소 배정

### 기호표 구성

- 선형리스트
  - 가장 간단하고 쉽게 구현할 수 있는 방법
  - 하나의 이름 삽입 = 1/2 * n = cn
  - 하나의 이름을 조회 = 1/2 * n = cn
  - m개의 이름을 조회 = cn * m
  - n개의 이름삽입과 m개의 이름조회에 필요한 시간: `cn * n + cn * m = cn * (n+m)`

- 트리
  - 이진트리 조회시간
  - 트리 평균 높이(조회에 필요한 평균시간)
    - log n에 비례 (n = 식별자 이름의 수)
    - n개의 이름 삽입 = n log n
    - m개의 이름 조회 = m log n
  - 전체시간: `(n+m)log n`에 비례
  - n > 50 이면 선형리스트보다 효율적

- 해쉬 테이블
  - 가장 효율이 좋은 검색법
  - 추가 및 조회 시간 = `n / k (m + n)` (n: 식별자 이름 추가, m: 조회, k: 해쉬테이블 index)
  - 해쉬 충돌발생시 처리방법?

### 상수정의와 의미분석

유형은 식별자의 종류

- CONSTID: 상수
- TYPEID: 각종타입
- SIMPLEVARID: 단순변수 유형
- FIELDID: record type에서 field-id-list 유형
- PROCID: 프로시저

상수정의 원시 프로그램 예시

```text
CONST
  X = 2;
  Z = -X;
```

어휘분석에서 다음 토큰으로 분리됨: `CONST, OTHERID, =, UNsigned_INTERGER`

기호표와 스택 포인터 값은 다음과 같다

- 인덱스: 이름: 유형
- K1: X: CONSTID
  - k2
  - new
  - `+`
- K2: 2: CONSTID
- K3: Z: CONSTID
  - k2
  - old
  - `-`

## 중간언어와 중간코드 생성

### 중간언어의 장점

- 컴파일러를 기능적으로 독립적인 여러 모듈들로 구성할 수 있따
- 원시 프로그래므이 이식성을 증가시킬 수 있다
- 고급 원시언어와 저급 목적코드 간의 의미적 차이를 이어주는 교량 역할
- 번역과정이 좀더 쉽게 표현되고 효율적으로 처리될 수 있다
- 기계와 독립적인 최적화가 가능하다
- 인터프리티브 컴파일링 시스템에서 인터프리터를 이용하여 실행할 수 있다
- 목적코드로 직접 번역한 것 보다 컴파일 시간이 더 소요되고 비효율적인 코드를 생성함

### 중간언어의 종류

- Polish 표기법: Postfix 표현, IR(Prefix 표현)
- 3-주소 코드
- Triple, Quadruple, 간접 Triple
- 트리구조 코드: AST, TCOL, Diana
- 가상 기계 코드
- P-코드, EM-코드, U-코드, 바이트코드

#### 후위(Postfix) 표현

`b * c - d`

- b * c - d
- b * c d -
- b c * d -

변환이 쉽고 빠르며 중간언어로 적합하나, 코드이동이 불가능하여 최적화 부적합

#### 3-주소 코드

치환문 `A:= -B * (C + D)`

- T1 := -B
- T2 := C + D
- T3 := T1 * T2
- A := T3

3주소 코드는 다음 방식이 존재

- TRIPLE: OP, 피연산자1, 피연산자2
- 간접 TRIPLE: 수행순서 + TRIPLE
- Quadruple: TRIPLE + 결과

### 구문지시적 변환(syntax-directed translation)

- 구문분석을 하면서 구문구조에 따라 직접 중간코드를 생산하는 방법
- 생성규칙 + 의미수행코드로 구성
- 생성규칙이 사용될 때 마다 의미수행 규칙을 수행하게 된다

#### 계산기 예제

입력문자열: 23*5+4$

|생성규칙 | 의미수행 규칙 |
| --- | --- |
| S -> E$ | {print E.VAL} |
| E -> E(1) + E(2) | {E.VAL := E(1).VAL + E(2).VAL} |
| E -> E(1) * E(2) | {E.VAL := E(1).VAL * E(2).VAL} |
| E -> (E(1)) | {E.VAL := E(1).VAL} |
| E -> I | {E.VAL := I.VAL} |
| E -> I(1) digit | {I.VAL := 10 * I(1).VAL + LEXVAL} |
| I -> digit | {I.VAL := LEXVAL} |

> digit: 0, 1, 2, ..., 9

### 중간코드 생성
